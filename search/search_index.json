{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SlimFit Documentation","text":"<p><code>slimfit</code> is inspired by symfit and internally also depends on  <code>sympy</code> but has some differences in API and functionality.</p> <p>Currently, <code>slimfit</code> is very barebones and supports only basic fitting, but advanced features such  as analytical calculation of jacobians, error estimation or constraints are not included. </p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from sympy import symbols\nfrom slimfit import Model, Fit, Parameter\nimport numpy as np\n\n# Generate some data\nxdata = np.linspace(0, 11, 25)\nydata = 0.5*xdata + 2.5\nydata += np.random.normal(0, scale= ydata / 10.0 + 0.2)\ndata = {'x': xdata, 'y': ydata}\n\n# Define model and parameters\ny, a, x, b = symbols('y a x b')\nmodel = Model({y: a*x + b})\nparameters = [\n    Parameter(a, guess=2.5),\n    Parameter(b, guess=1, lower_bound=0.)\n]\n\n# Fit the model\nfit = Fit(model, parameters, data)\nresult = fit.execute()\n\nprint(result.parameters)\n</code></pre>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages.\"\"\"\nfrom functools import partial\nfrom pathlib import Path\n\nimport mkdocs_gen_files\n\nROOT_DIR = \"slimfit\"\nnav = mkdocs_gen_files.Nav()\n\n# open_func = open # for debugging\nopen_func = mkdocs_gen_files.open\n</pre> \"\"\"Generate the code reference pages.\"\"\" from functools import partial from pathlib import Path  import mkdocs_gen_files  ROOT_DIR = \"slimfit\" nav = mkdocs_gen_files.Nav()  # open_func = open # for debugging open_func = mkdocs_gen_files.open In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(ROOT_DIR).rglob(\"*.py\")):  #\n    module_path = path.relative_to(ROOT_DIR).with_suffix(\"\")  #\n    doc_path = path.relative_to(ROOT_DIR).with_suffix(\".md\")  #\n\n    full_doc_path = Path(\"reference\", doc_path)  #\n\n    parts = list(module_path.parts)\n    if module_path.stem.startswith(\"_\"):\n        continue\n\n    nav[parts] = doc_path.as_posix()\n\n    with open_func(full_doc_path, \"w\") as fd:  #\n        identifier = \".\".join(parts)  #\n        print(\"::: \" + identifier, file=fd)  #\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, path)  #\n\n\nwith open_func(\"reference/SUMMARY.md\", \"w\") as nav_file:  #\n    nav_file.writelines(nav.build_literate_nav())\n</pre>  for path in sorted(Path(ROOT_DIR).rglob(\"*.py\")):  #     module_path = path.relative_to(ROOT_DIR).with_suffix(\"\")  #     doc_path = path.relative_to(ROOT_DIR).with_suffix(\".md\")  #      full_doc_path = Path(\"reference\", doc_path)  #      parts = list(module_path.parts)     if module_path.stem.startswith(\"_\"):         continue      nav[parts] = doc_path.as_posix()      with open_func(full_doc_path, \"w\") as fd:  #         identifier = \".\".join(parts)  #         print(\"::: \" + identifier, file=fd)  #      mkdocs_gen_files.set_edit_path(full_doc_path, path)  #   with open_func(\"reference/SUMMARY.md\", \"w\") as nav_file:  #     nav_file.writelines(nav.build_literate_nav())"},{"location":"installation/","title":"Installation","text":"<p>Install <code>slimfit</code> with pip:</p> <pre><code>pip install slimfit\n</code></pre>"},{"location":"structure/","title":"SlimFit Structure","text":"<p>Current sturcture of <code>slimfit</code> model-building classes:</p> <pre><code>graph LR;\nSymbolicBase --&gt; NumExprBase;\nSymbolicBase --&gt; CompositeExpr;\nNumExprBase --&gt; DummyNumExpr;\nNumExprBase --&gt; NumExpr;\nNumExprBase --&gt; LambdaNumExpr;\nNumExpr --&gt; MatrixNumExpr;\nCompositeExpr --&gt; Model;\nCompositeExpr --&gt; Eval;\nCompositeExpr --&gt; GMM;\nCompositeExpr --&gt; MarkovIVP;\nCompositeExpr --&gt; CompositeArgsExpr;\nCompositeArgsExpr --&gt; MatMul;\nCompositeArgsExpr --&gt; Mul;\nCompositeArgsExpr --&gt; Sum;\nCompositeArgsExpr --&gt; Add;</code></pre>"},{"location":"examples/basic_fit/","title":"Basic fit","text":"In\u00a0[\u00a0]: Copied! <pre>from slimfit import Fit, Model, Parameter\nfrom sympy import symbols\nimport numpy as np\nimport proplot as pplt\n\nfrom slimfit.objective import Hessian\n\na, b, x, y = symbols(\"a b x y\")\n\nmodel = Model({y: a * x + b})\nparameters = [\n    Parameter(a, guess=1.0),\n    Parameter(b, guess=3.0),\n]\n</pre> from slimfit import Fit, Model, Parameter from sympy import symbols import numpy as np import proplot as pplt  from slimfit.objective import Hessian  a, b, x, y = symbols(\"a b x y\")  model = Model({y: a * x + b}) parameters = [     Parameter(a, guess=1.0),     Parameter(b, guess=3.0), ] In\u00a0[\u00a0]: Copied! <pre># generate ground-truth data\ngt = {a: 0.5, b: 2.5}\nxdata = np.linspace(0, 11, num=100)\nydata = gt[a] * xdata + gt[b]\n\n# add noise\nnp.random.seed(43)\nnoise = np.random.normal(0, scale=ydata / 10.0 + 0.2)\nydata += noise\nDATA = {\"x\": xdata, \"y\": ydata}\n\nfit = Fit(model, parameters=parameters, data=DATA)\nresult = fit.execute()\nprint(result)\n</pre> # generate ground-truth data gt = {a: 0.5, b: 2.5} xdata = np.linspace(0, 11, num=100) ydata = gt[a] * xdata + gt[b]  # add noise np.random.seed(43) noise = np.random.normal(0, scale=ydata / 10.0 + 0.2) ydata += noise DATA = {\"x\": xdata, \"y\": ydata}  fit = Fit(model, parameters=parameters, data=DATA) result = fit.execute() print(result) In\u00a0[\u00a0]: Copied! <pre>fig, ax = pplt.subplots()\nax.scatter(xdata, ydata)\nax.plot(DATA[\"x\"], model(**result.parameters, **DATA)[\"y\"], color=\"r\")\nax.format(xlabel=\"x\", ylabel=\"y\")\npplt.show()\n</pre> fig, ax = pplt.subplots() ax.scatter(xdata, ydata) ax.plot(DATA[\"x\"], model(**result.parameters, **DATA)[\"y\"], color=\"r\") ax.format(xlabel=\"x\", ylabel=\"y\") pplt.show()"},{"location":"examples/custom_numexpr_ivp/","title":"Custom numerical expressions","text":"<p>This example shows how to use <code>CompositeExpr</code> to create a custom numerical expression which can be used in slimfit fitting.</p> <p>In this particular example we fit data to a dampened harmonic oscillator, where the time-evolution of the system is solved by <code>scipy.integrate.solve_ivp</code>.</p> <p>from future import annotations</p> <p>import numpy as np import proplot as pplt from scipy.integrate import solve_ivp from sympy import Symbol, Expr, symbols</p> <p>from slimfit import Model from slimfit.fit import Fit from slimfit.numerical import NumExpr, to_numerical from slimfit.base import CompositeExpr</p> In\u00a0[\u00a0]: Copied! <p>Generate the GT data to fit the damped harmonic oscillator to, and add some noise.</p> <p>def ode(x, y): return np.sin(2 * np.pi * 0.2 * x) * np.exp(-0.1 * x)</p> <p>num = 100 t_eval = np.linspace(0.0, 25, num=num, endpoint=True) sol = solve_ivp(ode, (0.0, 25), np.array([-1]), t_eval=t_eval)</p> <p>ydata = sol.y + np.random.normal(0, 0.05, size=num) data = {\"y\": ydata, \"t\": t_eval}</p> In\u00a0[\u00a0]: Copied! <p><code>CompositeExpr</code> can be subclassed to create a custom numerical expression. The subclass must implement the <code>__call__</code> method, which returns a (dictionary of) the numerical values of the expression. In this example, we use <code>solve_ivp</code> to solve the ODE, and return the solution at the specified time points.</p> <p>Because the <code>__init__</code> method takes an additional <code>domain</code> argument, the <code>to_numerical</code> method must also be implemented correctly.</p> <p>class IVPNumExpr(CompositeExpr): def init( self, t: Symbol | NumExpr | Expr, freq: Symbol | NumExpr | Expr, damping: Symbol | NumExpr | Expr, y0: Symbol | NumExpr | Expr, domain: tuple[float, float], ): expr = {\"t\": t, \"freq\": freq, \"damping\": damping, \"y0\": y0} self.domain = domain super().init(expr)</p> <pre><code>def __call__(self, *args, **kwargs) -&gt; np.ndarray:\n    result = super().__call__(**kwargs)\n\n    sol = solve_ivp(\n        self.grad_func,\n        self.domain,\n        np.array([result[\"y0\"]]),\n        t_eval=result[\"t\"],\n        args=(result[\"freq\"], result[\"damping\"]),\n    )\n\n    return sol.y\n\ndef to_numerical(self):\n    num_expr = {k: to_numerical(expr) for k, expr in self.items()}\n    instance = IVPNumExpr(**num_expr, domain=self.domain)\n\n    return instance\n\n@staticmethod\ndef grad_func(x, y, freq, damping):\n    return np.sin(2 * np.pi * freq * x) * np.exp(-damping * x)</code></pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>The resulting class can now be used in slimfit fitting, taking any symbol or expr as arguments for the args <code>t, f, d, y0</code>, or it can be embedded in a larger model.</p> <p>t, f, d, y0, y = symbols(\"t f d y0 y\") ivp = IVPNumExpr(t, f, d, y0, domain=(0.0, 25.0))</p> <p>model = Model({y: ivp})</p> <p>Fix frequency at GT value to ensure fit converges guess = {\"f\": 0.2, \"d\": 0.5, \"y0\": -1.0} parameters = model.define_parameters(guess).replace(\"f\", fixed=True)</p> <p>fit = Fit(model, parameters, data) result = fit.execute()</p> <p>print(result.parameters)</p> In\u00a0[\u00a0]: Copied! <pre>fig, ax = pplt.subplots()\nax.scatter(t_eval, ydata.flatten())\nax.plot(t_eval, ivp(t=t_eval, **parameters.guess).T, color=\"r\")\nax.plot(t_eval, ivp(t=t_eval, **result.parameters).T, color=\"k\")\npplt.show()\n</pre>  fig, ax = pplt.subplots() ax.scatter(t_eval, ydata.flatten()) ax.plot(t_eval, ivp(t=t_eval, **parameters.guess).T, color=\"r\") ax.plot(t_eval, ivp(t=t_eval, **result.parameters).T, color=\"k\") pplt.show()"},{"location":"examples/gaussian_mixture_model/","title":"Gaussian Mixture Model","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nfrom sympy import Symbol\nimport proplot as pplt\n\nfrom slimfit import Model\nfrom slimfit.numerical import GMM\nfrom slimfit.fit import Fit\nfrom slimfit.loss import LogSumLoss\nfrom slimfit.minimizers import LikelihoodOptimizer\nfrom slimfit.operations import Mul\nfrom slimfit.parameter import Parameters\nfrom slimfit.symbols import (\n    symbol_matrix,\n    clear_symbols,\n    get_symbols,\n)\n</pre> import numpy as np from sympy import Symbol import proplot as pplt  from slimfit import Model from slimfit.numerical import GMM from slimfit.fit import Fit from slimfit.loss import LogSumLoss from slimfit.minimizers import LikelihoodOptimizer from slimfit.operations import Mul from slimfit.parameter import Parameters from slimfit.symbols import (     symbol_matrix,     clear_symbols,     get_symbols, ) In\u00a0[\u00a0]: Copied! <pre>gt = {\n    \"mu_A\": 0.23,\n    \"mu_B\": 0.55,\n    \"mu_C\": 0.92,\n    \"sigma_A\": 0.1,\n    \"sigma_B\": 0.1,\n    \"sigma_C\": 0.1,\n    \"sigma_D\": 0.2,\n    \"c_A\": 0.22,\n    \"c_B\": 0.53,\n    \"c_C\": 0.25,\n}\n\nnp.random.seed(43)\nN = 1000\nstates = [\"A\", \"B\", \"C\"]\nxdata = np.concatenate(\n    [\n        np.random.normal(loc=gt[f\"mu_{s}\"], scale=gt[f\"sigma_{s}\"], size=int(N * gt[f\"c_{s}\"]))\n        for s in states\n    ]\n)\n\nnp.random.shuffle(xdata)\ndata = {\"x\": xdata.reshape(-1, 1)}\n</pre> gt = {     \"mu_A\": 0.23,     \"mu_B\": 0.55,     \"mu_C\": 0.92,     \"sigma_A\": 0.1,     \"sigma_B\": 0.1,     \"sigma_C\": 0.1,     \"sigma_D\": 0.2,     \"c_A\": 0.22,     \"c_B\": 0.53,     \"c_C\": 0.25, }  np.random.seed(43) N = 1000 states = [\"A\", \"B\", \"C\"] xdata = np.concatenate(     [         np.random.normal(loc=gt[f\"mu_{s}\"], scale=gt[f\"sigma_{s}\"], size=int(N * gt[f\"c_{s}\"]))         for s in states     ] )  np.random.shuffle(xdata) data = {\"x\": xdata.reshape(-1, 1)} In\u00a0[\u00a0]: Copied! <pre>guess = {\n    \"mu_A\": 0.2,\n    \"mu_B\": 0.4,\n    \"mu_C\": 0.7,\n    \"sigma_A\": 0.1,\n    \"sigma_B\": 0.1,\n    \"sigma_C\": 0.1,\n    \"c_A\": 0.33,\n    \"c_B\": 0.33,\n    \"c_C\": 0.33,\n}\n</pre> guess = {     \"mu_A\": 0.2,     \"mu_B\": 0.4,     \"mu_C\": 0.7,     \"sigma_A\": 0.1,     \"sigma_B\": 0.1,     \"sigma_C\": 0.1,     \"c_A\": 0.33,     \"c_B\": 0.33,     \"c_C\": 0.33, } In\u00a0[\u00a0]: Copied! <pre>clear_symbols()\n\ng_shape = (1, 3)\nc_shape = (3, 1)\nmu = symbol_matrix(name=\"mu\", shape=g_shape, suffix=states)\nsigma = symbol_matrix(name=\"sigma\", shape=g_shape, suffix=states)\nc = symbol_matrix(name=\"c\", shape=c_shape, suffix=states)\ngmm = GMM(Symbol(\"x\"), mu, sigma)\nmodel = Model({Symbol(\"p\"): Mul(c, gmm)})\n</pre> clear_symbols()  g_shape = (1, 3) c_shape = (3, 1) mu = symbol_matrix(name=\"mu\", shape=g_shape, suffix=states) sigma = symbol_matrix(name=\"sigma\", shape=g_shape, suffix=states) c = symbol_matrix(name=\"c\", shape=c_shape, suffix=states) gmm = GMM(Symbol(\"x\"), mu, sigma) model = Model({Symbol(\"p\"): Mul(c, gmm)}) In\u00a0[\u00a0]: Copied! <pre>symbols = get_symbols(mu, sigma, c)\nparameters = Parameters.from_symbols(symbols.values(), guess)\n</pre> symbols = get_symbols(mu, sigma, c) parameters = Parameters.from_symbols(symbols.values(), guess) In\u00a0[\u00a0]: Copied! <pre>fit = Fit(model, parameters, data, loss=LogSumLoss(sum_axis=1))\nresult = fit.execute(minimizer=LikelihoodOptimizer)\n\n# Compare fit result with ground truth parameters\nfor k, v in result.fit_parameters.items():\n    print(f\"{k:5}: {v:10.2}, ({gt[k]:10.2})\")\n</pre> fit = Fit(model, parameters, data, loss=LogSumLoss(sum_axis=1)) result = fit.execute(minimizer=LikelihoodOptimizer)  # Compare fit result with ground truth parameters for k, v in result.fit_parameters.items():     print(f\"{k:5}: {v:10.2}, ({gt[k]:10.2})\") In\u00a0[\u00a0]: Copied! <pre>x_eval = np.linspace(-0.2, 1.3, num=250, endpoint=True)\ny_eval = model(**result.parameters, x=x_eval.reshape(-1, 1))[\"p\"].squeeze()\n\ny_eval.shape\n</pre> x_eval = np.linspace(-0.2, 1.3, num=250, endpoint=True) y_eval = model(**result.parameters, x=x_eval.reshape(-1, 1))[\"p\"].squeeze()  y_eval.shape In\u00a0[\u00a0]: Copied! <pre>fig, ax = pplt.subplots()\nax.hist(data[\"x\"], bins=\"fd\", density=True, color=\"grey\")\nax.plot(x_eval, y_eval)\nax.plot(x_eval, y_eval.sum(axis=1), color=\"k\", linestyle=\"--\", alpha=0.75)\nax.format(xlabel=\"x\", ylabel=\"p(x)\", title=\"GMM Likelihood Fit\")\npplt.show()\n</pre> fig, ax = pplt.subplots() ax.hist(data[\"x\"], bins=\"fd\", density=True, color=\"grey\") ax.plot(x_eval, y_eval) ax.plot(x_eval, y_eval.sum(axis=1), color=\"k\", linestyle=\"--\", alpha=0.75) ax.format(xlabel=\"x\", ylabel=\"p(x)\", title=\"GMM Likelihood Fit\") pplt.show()"},{"location":"examples/gmm_amplitudes/","title":"GMM amplitudes","text":"<p>Given known gaussian mixture model parameters, find best fit parameters for their amplitudes.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nfrom sympy import Symbol\n\nfrom slimfit import Model\n\nfrom slimfit.numerical import GMM\nfrom slimfit.fit import Fit\nfrom slimfit.loss import LogSumLoss\nfrom slimfit.minimizers import LikelihoodOptimizer\nfrom slimfit.operations import Mul\nfrom slimfit.parameter import Parameters\nfrom slimfit.symbols import (\n    symbol_matrix,\n    clear_symbols,\n    get_symbols,\n)\n</pre>  import numpy as np from sympy import Symbol  from slimfit import Model  from slimfit.numerical import GMM from slimfit.fit import Fit from slimfit.loss import LogSumLoss from slimfit.minimizers import LikelihoodOptimizer from slimfit.operations import Mul from slimfit.parameter import Parameters from slimfit.symbols import (     symbol_matrix,     clear_symbols,     get_symbols, ) In\u00a0[\u00a0]: Copied! <pre>gt = {\n    \"mu_A\": 0.23,\n    \"mu_B\": 0.55,\n    \"mu_C\": 0.92,\n    \"sigma_A\": 0.1,\n    \"sigma_B\": 0.1,\n    \"sigma_C\": 0.1,\n    \"c_A\": 0.22,\n    \"c_B\": 0.53,\n    \"c_C\": 0.25,\n}\n\nnp.random.seed(43)\nN = 1000\nstates = [\"A\", \"B\", \"C\"]\nxdata = np.concatenate(\n    [\n        np.random.normal(loc=gt[f\"mu_{s}\"], scale=gt[f\"sigma_{s}\"], size=int(N * gt[f\"c_{s}\"]))\n        for s in states\n    ]\n)\n\nnp.random.shuffle(xdata)\ndata = {\"x\": xdata.reshape(-1, 1)}\n</pre> gt = {     \"mu_A\": 0.23,     \"mu_B\": 0.55,     \"mu_C\": 0.92,     \"sigma_A\": 0.1,     \"sigma_B\": 0.1,     \"sigma_C\": 0.1,     \"c_A\": 0.22,     \"c_B\": 0.53,     \"c_C\": 0.25, }  np.random.seed(43) N = 1000 states = [\"A\", \"B\", \"C\"] xdata = np.concatenate(     [         np.random.normal(loc=gt[f\"mu_{s}\"], scale=gt[f\"sigma_{s}\"], size=int(N * gt[f\"c_{s}\"]))         for s in states     ] )  np.random.shuffle(xdata) data = {\"x\": xdata.reshape(-1, 1)} In\u00a0[\u00a0]: Copied! <pre>guess = {\n    \"c_A\": 0.33,\n    \"c_B\": 0.33,\n    \"c_C\": 0.33,\n}\n</pre> guess = {     \"c_A\": 0.33,     \"c_B\": 0.33,     \"c_C\": 0.33, } In\u00a0[\u00a0]: Copied! <pre>clear_symbols()\n</pre> clear_symbols() In\u00a0[\u00a0]: Copied! <pre>g_shape = (1, 3)\nc_shape = (3, 1)\nmu = symbol_matrix(name=\"mu\", shape=g_shape, suffix=states)\nsigma = symbol_matrix(name=\"sigma\", shape=g_shape, suffix=states)\nc = symbol_matrix(name=\"c\", shape=c_shape, suffix=states)\ngmm = GMM(Symbol(\"x\"), mu, sigma)\n\n# pre-evaluate the GMM part\nnum_gmm = gmm.numerical(**data, **gt)\n</pre> g_shape = (1, 3) c_shape = (3, 1) mu = symbol_matrix(name=\"mu\", shape=g_shape, suffix=states) sigma = symbol_matrix(name=\"sigma\", shape=g_shape, suffix=states) c = symbol_matrix(name=\"c\", shape=c_shape, suffix=states) gmm = GMM(Symbol(\"x\"), mu, sigma)  # pre-evaluate the GMM part num_gmm = gmm.numerical(**data, **gt) In\u00a0[\u00a0]: Copied! <pre># The model now only has amplitude parameters\nmodel = Model({Symbol(\"p\"): Mul(c, num_gmm)})\n</pre> # The model now only has amplitude parameters model = Model({Symbol(\"p\"): Mul(c, num_gmm)}) In\u00a0[\u00a0]: Copied! <pre>symbols = get_symbols(mu, sigma, c)\nparameters = model.define_parameters(guess)\n\nfit = Fit(model, parameters, data, loss=LogSumLoss(sum_axis=1))\nresult = fit.execute(minimizer=LikelihoodOptimizer)\n\n# Compare fit result with ground truth parameters\nfor k, v in result.parameters.items():\n    print(f\"{k:5}: {v:10.2}, ({gt[k]:10.2})\")\n</pre> symbols = get_symbols(mu, sigma, c) parameters = model.define_parameters(guess)  fit = Fit(model, parameters, data, loss=LogSumLoss(sum_axis=1)) result = fit.execute(minimizer=LikelihoodOptimizer)  # Compare fit result with ground truth parameters for k, v in result.parameters.items():     print(f\"{k:5}: {v:10.2}, ({gt[k]:10.2})\")"},{"location":"examples/likelihood_gaussian/","title":"Likelihood fit","text":"<p>Likelihood fitting of normally distributed samples.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport proplot as pplt\n\nfrom slimfit.symbols import Symbol\nfrom slimfit.models import Model\nfrom slimfit.fit import Fit\nfrom slimfit.functions import gaussian_sympy\nfrom slimfit.loss import LogLoss\n</pre> import numpy as np import proplot as pplt  from slimfit.symbols import Symbol from slimfit.models import Model from slimfit.fit import Fit from slimfit.functions import gaussian_sympy from slimfit.loss import LogLoss In\u00a0[\u00a0]: Copied! <pre>gt_params = {\"mu\": 2.4, \"sigma\": 0.7}\n\nxdata = np.random.normal(gt_params[\"mu\"], scale=gt_params[\"sigma\"], size=500)\nmodel = Model({Symbol(\"p\"): gaussian_sympy(Symbol(\"x\"), Symbol(\"mu\"), Symbol(\"sigma\"))})\n</pre>  gt_params = {\"mu\": 2.4, \"sigma\": 0.7}  xdata = np.random.normal(gt_params[\"mu\"], scale=gt_params[\"sigma\"], size=500) model = Model({Symbol(\"p\"): gaussian_sympy(Symbol(\"x\"), Symbol(\"mu\"), Symbol(\"sigma\"))}) In\u00a0[\u00a0]: Copied! <pre>parameters = model.define_parameters(\"mu sigma\")\n</pre> parameters = model.define_parameters(\"mu sigma\") In\u00a0[\u00a0]: Copied! <pre>fit = Fit(model, parameters, data={\"x\": xdata}, loss=LogLoss())\n\n# execution time: 12.5ms\nlikelihood_result = fit.execute()\n</pre> fit = Fit(model, parameters, data={\"x\": xdata}, loss=LogLoss())  # execution time: 12.5ms likelihood_result = fit.execute() In\u00a0[\u00a0]: Copied! <pre>hist, edges = np.histogram(xdata, bins=\"fd\", density=True)\ncenters = (edges[:-1] + edges[1:]) / 2.0\ncenters, edges\n</pre>  hist, edges = np.histogram(xdata, bins=\"fd\", density=True) centers = (edges[:-1] + edges[1:]) / 2.0 centers, edges In\u00a0[\u00a0]: Copied! <pre>fig, ax = pplt.subplots()\nax.scatter(centers, hist, color=\"r\")\nax.hist(xdata, bins=\"fd\", density=True, color=\"gray\")\npplt.show()\n</pre>  fig, ax = pplt.subplots() ax.scatter(centers, hist, color=\"r\") ax.hist(xdata, bins=\"fd\", density=True, color=\"gray\") pplt.show() In\u00a0[\u00a0]: Copied! <pre>fit = Fit(model, parameters, data={\"x\": centers, \"p\": hist})\nbinned_lsq_result = fit.execute()\nprint(binned_lsq_result)\n</pre> fit = Fit(model, parameters, data={\"x\": centers, \"p\": hist}) binned_lsq_result = fit.execute() print(binned_lsq_result) In\u00a0[\u00a0]: Copied! <pre>binned_lsq_result.guess\n</pre> binned_lsq_result.guess In\u00a0[\u00a0]: Copied! <pre>print(likelihood_result.hessian)\nprint(binned_lsq_result.hessian)\n</pre> print(likelihood_result.hessian) print(binned_lsq_result.hessian) In\u00a0[\u00a0]: Copied! <pre>data = {\"x\": np.linspace(0.0, 5.0, num=100)}\n\nfig, ax = pplt.subplots()\nax.plot(data[\"x\"], model(**gt_params, **data)[\"p\"], color=\"r\")\nax.plot(\n    data[\"x\"],\n    model(**likelihood_result.parameters, **data)[\"p\"],\n    linestyle=\"--\",\n    color=\"k\",\n    label=\"likelihood\",\n)\nax.plot(\n    data[\"x\"],\n    model(**binned_lsq_result.parameters, **data)[\"p\"],\n    linestyle=\"--\",\n    color=\"b\",\n    label=\"lsq\",\n)\n\nax.hist(xdata, bins=\"fd\", density=True, color=\"grey\", zorder=-1)\nax.scatter(centers, hist, color=\"b\", marker=\"x\")\nax.format(xlabel=\"x\", ylabel=\"p(x)\", title=\"Gaussian Fit\")\nax.legend(loc=\"t\")\npplt.show()\n</pre> data = {\"x\": np.linspace(0.0, 5.0, num=100)}  fig, ax = pplt.subplots() ax.plot(data[\"x\"], model(**gt_params, **data)[\"p\"], color=\"r\") ax.plot(     data[\"x\"],     model(**likelihood_result.parameters, **data)[\"p\"],     linestyle=\"--\",     color=\"k\",     label=\"likelihood\", ) ax.plot(     data[\"x\"],     model(**binned_lsq_result.parameters, **data)[\"p\"],     linestyle=\"--\",     color=\"b\",     label=\"lsq\", )  ax.hist(xdata, bins=\"fd\", density=True, color=\"grey\", zorder=-1) ax.scatter(centers, hist, color=\"b\", marker=\"x\") ax.format(xlabel=\"x\", ylabel=\"p(x)\", title=\"Gaussian Fit\") ax.legend(loc=\"t\") pplt.show()"},{"location":"examples/linear_matrices/","title":"Linear combinations","text":"<p>This example assumes a measured spectrum which is a linear combination of known basis vectors (which are here modelled as Gaussians). The goal is to find the coefficients of the linear combinations.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\nfrom slimfit import Model\nfrom slimfit.fit import Fit\nfrom slimfit.functions import gaussian_numpy\n\nfrom slimfit.operations import MatMul\nfrom slimfit.parameter import Parameters\nfrom slimfit.symbols import symbol_matrix, Symbol\n\nimport proplot as pplt\n</pre> import numpy as np  from slimfit import Model from slimfit.fit import Fit from slimfit.functions import gaussian_numpy  from slimfit.operations import MatMul from slimfit.parameter import Parameters from slimfit.symbols import symbol_matrix, Symbol  import proplot as pplt <p>Generating the basis vectors from Gaussians, create spectrum from given ground-truth coefficients.</p> In\u00a0[\u00a0]: Copied! <pre># Generate the basis vectors, modelled as gaussian peaks\nmu_vals = [1.1, 3.5, 7.2]\nsigma_vals = [0.25, 0.1, 0.72]\nwavenumber = np.linspace(0, 11, num=100)  # wavenumber x-axis\nbasis = np.stack(\n    [gaussian_numpy(wavenumber, mu_i, sig_i) for mu_i, sig_i in zip(mu_vals, sigma_vals)]\n).T\nbasis.shape\n</pre> # Generate the basis vectors, modelled as gaussian peaks mu_vals = [1.1, 3.5, 7.2] sigma_vals = [0.25, 0.1, 0.72] wavenumber = np.linspace(0, 11, num=100)  # wavenumber x-axis basis = np.stack(     [gaussian_numpy(wavenumber, mu_i, sig_i) for mu_i, sig_i in zip(mu_vals, sigma_vals)] ).T basis.shape In\u00a0[\u00a0]: Copied! <pre># Ground-truth coefficients we want to find\nx_vals = np.array([0.3, 0.5, 0.2]).reshape(3, 1)  # unknowns\n\n# Simulated measured spectrum given ground-truth coefficients and basis vectors\nspectrum = basis @ np.array(x_vals).reshape(3, 1)\nspectrum += np.random.normal(0, 0.1, size=spectrum.shape)  # add noise\n\nspectrum.shape\n</pre> # Ground-truth coefficients we want to find x_vals = np.array([0.3, 0.5, 0.2]).reshape(3, 1)  # unknowns  # Simulated measured spectrum given ground-truth coefficients and basis vectors spectrum = basis @ np.array(x_vals).reshape(3, 1) spectrum += np.random.normal(0, 0.1, size=spectrum.shape)  # add noise  spectrum.shape <p>The model describing the spectrum is of form $Ax = b$; where $A$ is the matrix of stacked basis vectors, $x$ is the coefficient vector we want to find and $b$ is the measured spectrum.</p> <p>We can define the model in two ways:</p> <p>Option 1: Create sympy Matrix with coefficients and multiply it with the array of coefficients.</p> In\u00a0[\u00a0]: Copied! <pre># Create a sympy matrix with parameters are elements with shape (3, 1)\nx = symbol_matrix(name=\"X\", shape=(3, 1))\nparameters = Parameters.from_symbols(x.free_symbols)\nx, type(x)\n</pre> # Create a sympy matrix with parameters are elements with shape (3, 1) x = symbol_matrix(name=\"X\", shape=(3, 1)) parameters = Parameters.from_symbols(x.free_symbols) x, type(x) In\u00a0[\u00a0]: Copied! <pre># Matrix multiply basis matrix with parameter vector\nm = basis @ x\n# define the model, measured spectrum corresponds to Symbol('b')mod\nmodel = Model({Symbol(\"b\"): basis @ x})\ntype(model[Symbol(\"b\")])\n</pre> # Matrix multiply basis matrix with parameter vector m = basis @ x # define the model, measured spectrum corresponds to Symbol('b')mod model = Model({Symbol(\"b\"): basis @ x}) type(model[Symbol(\"b\")]) In\u00a0[\u00a0]: Copied! <pre>fit = Fit(model, parameters, data={\"b\": spectrum})\nresult = fit.execute()  # execution time 117 ms\nresult.parameters\n</pre> fit = Fit(model, parameters, data={\"b\": spectrum}) result = fit.execute()  # execution time 117 ms result.parameters <p>This works but is performance-wise not desirable as the matrix in the model is shape (100, 1). Calling the model currently is implemented by lambdifying the matrix element-wise, this requires 100 lambda functions to be evaluated, and their result to be placed in an array through a for loop.</p> <p>Option 2: Evaluate the matrix multiplication lazily with <code>MatMul</code></p> In\u00a0[\u00a0]: Copied! <pre>m = MatMul(basis, x)\nmodel = Model({Symbol(\"b\"): m})\ntype(model[Symbol(\"b\")])\n</pre> m = MatMul(basis, x) model = Model({Symbol(\"b\"): m}) type(model[Symbol(\"b\")]) In\u00a0[\u00a0]: Copied! <pre>fit = Fit(model, parameters, data={\"b\": spectrum})\nresult = fit.execute()  # execution time: 15.2 ms\n</pre> fit = Fit(model, parameters, data={\"b\": spectrum}) result = fit.execute()  # execution time: 15.2 ms In\u00a0[\u00a0]: Copied! <pre>for i, j in np.ndindex(x_vals.shape):\n    print(x_vals[i, j], result.parameters[f\"X_{i}_{j}\"])\n</pre> for i, j in np.ndindex(x_vals.shape):     print(x_vals[i, j], result.parameters[f\"X_{i}_{j}\"]) <p>The second option is 10 times faster as only a 3x1 matrix is evaluated through element-wise lambdification. The matrix multiplication step is done in numpy, and is fast.</p> <p>Plotting the results:</p> In\u00a0[\u00a0]: Copied! <pre>fig, ax = pplt.subplots()\nax.plot(wavenumber, spectrum, color=\"k\")\nax.plot(wavenumber, model(**result.parameters)[\"b\"], color=\"r\", lw=1, alpha=0.75)\nax.format(xlabel=\"wavenumber\", ylabel=\"intensity\", title=\"Linear combination Fit\")\npplt.show()\n</pre>  fig, ax = pplt.subplots() ax.plot(wavenumber, spectrum, color=\"k\") ax.plot(wavenumber, model(**result.parameters)[\"b\"], color=\"r\", lw=1, alpha=0.75) ax.format(xlabel=\"wavenumber\", ylabel=\"intensity\", title=\"Linear combination Fit\") pplt.show()"},{"location":"examples/markov_chain/","title":"Markov chain","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nFitting of Markov chain process solved by matrix exponentiation.\n\"\"\"\n\nfrom typing import Callable, Optional\n\nfrom slimfit.fit import Fit\nfrom slimfit.loss import SELoss\nfrom slimfit.markov import generate_transition_matrix, extract_states\nfrom slimfit.numerical import MarkovIVP\nfrom slimfit.objective import Hessian\nfrom slimfit.parameter import Parameters\nfrom slimfit.symbols import symbol_matrix, get_symbols\nfrom slimfit.models import Model\nimport numpy as np\nimport proplot as pplt\nfrom sympy import Matrix, lambdify, exp, Symbol\n</pre>  \"\"\" Fitting of Markov chain process solved by matrix exponentiation. \"\"\"  from typing import Callable, Optional  from slimfit.fit import Fit from slimfit.loss import SELoss from slimfit.markov import generate_transition_matrix, extract_states from slimfit.numerical import MarkovIVP from slimfit.objective import Hessian from slimfit.parameter import Parameters from slimfit.symbols import symbol_matrix, get_symbols from slimfit.models import Model import numpy as np import proplot as pplt from sympy import Matrix, lambdify, exp, Symbol In\u00a0[\u00a0]: Copied! <pre>np.random.seed(43)\n</pre> np.random.seed(43) In\u00a0[\u00a0]: Copied! <pre># Ground truth parameter values for generating data and fitting\ngt_values = {\n    \"k_A_B\": 1e0,\n    \"k_B_A\": 5e-2,\n    \"k_B_C\": 5e-1,\n    \"y0_A\": 1.0,\n    \"y0_B\": 0.0,\n    \"y0_C\": 0.0,\n}\n</pre> # Ground truth parameter values for generating data and fitting gt_values = {     \"k_A_B\": 1e0,     \"k_B_A\": 5e-2,     \"k_B_C\": 5e-1,     \"y0_A\": 1.0,     \"y0_B\": 0.0,     \"y0_C\": 0.0, } In\u00a0[\u00a0]: Copied! <pre># Generate markov chain transition rate matrix from state connectivity string(s)\nconnectivity = [\"A &lt;-&gt; B -&gt; C\"]\n\nm = generate_transition_matrix(connectivity)\nstates = extract_states(connectivity)\n\ny0 = symbol_matrix(name=\"y0\", shape=(3, 1), suffix=states)\n\n# model for markov chain\nxt = exp(m * Symbol(\"t\"))\nmodel = Model({Symbol(\"y\"): xt @ y0})\n</pre> # Generate markov chain transition rate matrix from state connectivity string(s) connectivity = [\"A &lt;-&gt; B -&gt; C\"]  m = generate_transition_matrix(connectivity) states = extract_states(connectivity)  y0 = symbol_matrix(name=\"y0\", shape=(3, 1), suffix=states)  # model for markov chain xt = exp(m * Symbol(\"t\")) model = Model({Symbol(\"y\"): xt @ y0}) In\u00a0[\u00a0]: Copied! <pre>rate_params = Parameters.from_symbols(m.free_symbols)\ny0_params = Parameters.from_symbols(y0.free_symbols)\nparameters = rate_params + y0_params\n\nparameters\n</pre>  rate_params = Parameters.from_symbols(m.free_symbols) y0_params = Parameters.from_symbols(y0.free_symbols) parameters = rate_params + y0_params  parameters In\u00a0[\u00a0]: Copied! <pre># Generate data with 50 datapoints per population\nnum = 50\nxdata = {\"t\": np.linspace(0, 11, num=num)}\n\n# Calling a matrix based model expands the dimensions of the matrix on the first axis to\n# match the shape of input variables or parameters.\nnum_model = model.to_numerical()\npopulations = num_model(**gt_values, **xdata)[\"y\"]\npopulations.shape\n</pre> # Generate data with 50 datapoints per population num = 50 xdata = {\"t\": np.linspace(0, 11, num=num)}  # Calling a matrix based model expands the dimensions of the matrix on the first axis to # match the shape of input variables or parameters. num_model = model.to_numerical() populations = num_model(**gt_values, **xdata)[\"y\"] populations.shape In\u00a0[\u00a0]: Copied! <pre># # add noise to populations\nydata = {\"y\": populations + np.random.normal(0, 0.05, size=num * 3).reshape(populations.shape)}\nydata[\"y\"].shape  # shape of the data is (50, 3, 1)\n</pre>  # # add noise to populations ydata = {\"y\": populations + np.random.normal(0, 0.05, size=num * 3).reshape(populations.shape)} ydata[\"y\"].shape  # shape of the data is (50, 3, 1) In\u00a0[\u00a0]: Copied! <pre># fit the model to the data\n# loss function uses 'mean' reduction as the fitting does not converge with 'sum' reduction\nfit = Fit(model, parameters, data={**xdata, **ydata}, loss=SELoss(reduction=\"mean\"))\nresult = fit.execute()\nprint(result)\n</pre> # fit the model to the data # loss function uses 'mean' reduction as the fitting does not converge with 'sum' reduction fit = Fit(model, parameters, data={**xdata, **ydata}, loss=SELoss(reduction=\"mean\")) result = fit.execute() print(result) In\u00a0[\u00a0]: Copied! <pre># to calculate variances and standard deviations of the parameters, the hessian matrix\n# needs to be evaluated with the sum of squared errors as loss function.\nhessian = Hessian(\n    model,\n    loss=SELoss(reduction=\"sum\"),\n    xdata=fit.xdata,\n    ydata=fit.ydata,\n    shapes=parameters.free.shapes,\n)\nhessian\n</pre> # to calculate variances and standard deviations of the parameters, the hessian matrix # needs to be evaluated with the sum of squared errors as loss function. hessian = Hessian(     model,     loss=SELoss(reduction=\"sum\"),     xdata=fit.xdata,     ydata=fit.ydata,     shapes=parameters.free.shapes, ) hessian In\u00a0[\u00a0]: Copied! <pre>result.eval_hessian(hessian)\nprint(result)\n</pre>  result.eval_hessian(hessian) print(result) In\u00a0[\u00a0]: Copied! <pre># Compare fit result with ground truth parameters\nfor k, v in result.parameters.items():\n    print(f\"{k:5}: {v:10.2}, ({gt_values[k]:10.2})\")\n</pre> # Compare fit result with ground truth parameters for k, v in result.parameters.items():     print(f\"{k:5}: {v:10.2}, ({gt_values[k]:10.2})\") In\u00a0[\u00a0]: Copied! <pre># Expected:\n# k_A_B:        1.1, (       1.0)\n# k_B_A:      0.026, (      0.05)\n# k_B_C:       0.49, (       0.5)\n# y0_A :        1.0, (       1.0)\n# y0_B :     -0.012, (       0.0)\n# y0_C :    -0.0064, (       0.0)\n# k_A_B:        1.1, (       1.0)\n# k_B_A:      0.025, (      0.05)\n# k_B_C:       0.49, (       0.5)\n# y0_A :        1.0, (       1.0)\n# y0_B :     -0.011, (       0.0)\n# y0_C :    -0.0064, (       0.0)\n</pre>  # Expected: # k_A_B:        1.1, (       1.0) # k_B_A:      0.026, (      0.05) # k_B_C:       0.49, (       0.5) # y0_A :        1.0, (       1.0) # y0_B :     -0.012, (       0.0) # y0_C :    -0.0064, (       0.0) # k_A_B:        1.1, (       1.0) # k_B_A:      0.025, (      0.05) # k_B_C:       0.49, (       0.5) # y0_A :        1.0, (       1.0) # y0_B :     -0.011, (       0.0) # y0_C :    -0.0064, (       0.0) In\u00a0[\u00a0]: Copied! <pre># compare input data to fitted population dynamics in a graph\ncolor = [\"#7FACFA\", \"#FA654D\", \"#8CAD36\"]\ncycle = pplt.Cycle(color=color)\n\neval_data = {\"t\": np.linspace(0, 11, 1000)}\ny_eval = model(**result.parameters, **eval_data)[\"y\"]\n\nfig, ax = pplt.subplots()\nax.scatter(xdata[\"t\"], ydata[\"y\"].squeeze(), cycle=cycle)\nax.line(eval_data[\"t\"], y_eval.squeeze(), cycle=cycle)\nax.format(xlabel=\"Time\", ylabel=\"Population Fraction\")\npplt.show()\n</pre>  # compare input data to fitted population dynamics in a graph color = [\"#7FACFA\", \"#FA654D\", \"#8CAD36\"] cycle = pplt.Cycle(color=color)  eval_data = {\"t\": np.linspace(0, 11, 1000)} y_eval = model(**result.parameters, **eval_data)[\"y\"]  fig, ax = pplt.subplots() ax.scatter(xdata[\"t\"], ydata[\"y\"].squeeze(), cycle=cycle) ax.line(eval_data[\"t\"], y_eval.squeeze(), cycle=cycle) ax.format(xlabel=\"Time\", ylabel=\"Population Fraction\") pplt.show() In\u00a0[\u00a0]: Copied! <pre># repeat the fit with numerical integration of the markov model using `scipy.integrate.solve_ivp`\nivp_model = Model({Symbol(\"y\"): MarkovIVP(Symbol(\"t\"), m, y0)})\nfit = Fit(ivp_model, parameters, data={**xdata, **ydata})\nivp_result = fit.execute()\n</pre>  # repeat the fit with numerical integration of the markov model using `scipy.integrate.solve_ivp` ivp_model = Model({Symbol(\"y\"): MarkovIVP(Symbol(\"t\"), m, y0)}) fit = Fit(ivp_model, parameters, data={**xdata, **ydata}) ivp_result = fit.execute() In\u00a0[\u00a0]: Copied! <pre>ivp_result.eval_hessian()\nprint(ivp_result)\n</pre> ivp_result.eval_hessian() print(ivp_result) In\u00a0[\u00a0]: Copied! <pre>np.linalg.inv(ivp_result.hess)\n</pre>  np.linalg.inv(ivp_result.hess) In\u00a0[\u00a0]: Copied! <pre># Compare fit result with ground truth parameters\nfor k, v in ivp_result.parameters.items():\n    print(f\"{k:5}: {v:10.2}, ({gt_values[k]:10.2})\")\n</pre>  # Compare fit result with ground truth parameters for k, v in ivp_result.parameters.items():     print(f\"{k:5}: {v:10.2}, ({gt_values[k]:10.2})\") In\u00a0[\u00a0]: Copied! <pre># compare input data to fitted population dynamics in a graph\ncolor = [\"#7FACFA\", \"#FA654D\", \"#8CAD36\"]\ncycle = pplt.Cycle(color=color)\n\neval_data = {\"t\": np.linspace(0, 11, 1000)}\ny_eval = ivp_model(**ivp_result.parameters, **eval_data)[\"y\"]\n\nfig, ax = pplt.subplots()\nax.scatter(xdata[\"t\"], ydata[\"y\"].squeeze(), cycle=cycle)\nax.line(eval_data[\"t\"], y_eval.squeeze(), cycle=cycle)\nax.format(xlabel=\"Time\", ylabel=\"Population Fraction\")\npplt.show()\n</pre> # compare input data to fitted population dynamics in a graph color = [\"#7FACFA\", \"#FA654D\", \"#8CAD36\"] cycle = pplt.Cycle(color=color)  eval_data = {\"t\": np.linspace(0, 11, 1000)} y_eval = ivp_model(**ivp_result.parameters, **eval_data)[\"y\"]  fig, ax = pplt.subplots() ax.scatter(xdata[\"t\"], ydata[\"y\"].squeeze(), cycle=cycle) ax.line(eval_data[\"t\"], y_eval.squeeze(), cycle=cycle) ax.format(xlabel=\"Time\", ylabel=\"Population Fraction\") pplt.show()"},{"location":"examples/markov_chain_and_GMM/","title":"Markov and GMM","text":"In\u00a0[\u00a0]: Copied! <pre>import proplot as pplt\nfrom sympy import Matrix, exp\nimport numpy as np\n\nfrom slimfit.numerical import GMM\n\nfrom slimfit.fit import Fit\nfrom slimfit.loss import LogSumLoss\nfrom slimfit.markov import generate_transition_matrix, extract_states\nfrom slimfit.minimizers import LikelihoodOptimizer\nfrom slimfit.models import Model\nfrom slimfit.objective import Hessian\nfrom slimfit.operations import Mul\nfrom slimfit.parameter import Parameters\nfrom slimfit.symbols import clear_symbols, symbol_matrix, Symbol\n</pre> import proplot as pplt from sympy import Matrix, exp import numpy as np  from slimfit.numerical import GMM  from slimfit.fit import Fit from slimfit.loss import LogSumLoss from slimfit.markov import generate_transition_matrix, extract_states from slimfit.minimizers import LikelihoodOptimizer from slimfit.models import Model from slimfit.objective import Hessian from slimfit.operations import Mul from slimfit.parameter import Parameters from slimfit.symbols import clear_symbols, symbol_matrix, Symbol In\u00a0[\u00a0]: Copied! <pre>arr = np.genfromtxt(r\"C:\\Users\\jhsmi\\pp\\slimfit\\examples\\data\\GMM_dynamics.txt\")\ndata = {\"e\": arr[:, 0].reshape(-1, 1), \"t\": arr[:, 1]}\n\ngt_values = {\n    \"k_A_B\": 5e-1,\n    \"k_B_A\": 5e-2,\n    \"k_B_C\": 2.5e-1,\n    \"y0_A\": 1.0,\n    \"y0_B\": 0.0,\n    \"mu_A\": 0.82,\n    \"mu_B\": 0.13,\n    \"mu_C\": 0.55,\n    \"sigma_A\": 0.095,\n    \"sigma_B\": 0.12,\n    \"sigma_C\": 0.08,\n}\n\nguess_values = {\n    \"k_A_B\": 1e-1,\n    \"k_B_A\": 1e-1,\n    \"k_B_C\": 1e-1,\n    \"y0_A\": 0.6,\n    \"y0_B\": 0.0,\n    \"mu_A\": 0.7,\n    \"mu_B\": 0.05,\n    \"mu_C\": 0.4,\n    \"sigma_A\": 0.1,\n    \"sigma_B\": 0.2,\n    \"sigma_C\": 0.1,\n}\n</pre>  arr = np.genfromtxt(r\"C:\\Users\\jhsmi\\pp\\slimfit\\examples\\data\\GMM_dynamics.txt\") data = {\"e\": arr[:, 0].reshape(-1, 1), \"t\": arr[:, 1]}  gt_values = {     \"k_A_B\": 5e-1,     \"k_B_A\": 5e-2,     \"k_B_C\": 2.5e-1,     \"y0_A\": 1.0,     \"y0_B\": 0.0,     \"mu_A\": 0.82,     \"mu_B\": 0.13,     \"mu_C\": 0.55,     \"sigma_A\": 0.095,     \"sigma_B\": 0.12,     \"sigma_C\": 0.08, }  guess_values = {     \"k_A_B\": 1e-1,     \"k_B_A\": 1e-1,     \"k_B_C\": 1e-1,     \"y0_A\": 0.6,     \"y0_B\": 0.0,     \"mu_A\": 0.7,     \"mu_B\": 0.05,     \"mu_C\": 0.4,     \"sigma_A\": 0.1,     \"sigma_B\": 0.2,     \"sigma_C\": 0.1, } In\u00a0[\u00a0]: Copied! <pre>clear_symbols()\n\nconnectivity = [\"A &lt;-&gt; B -&gt; C\"]\nm = generate_transition_matrix(connectivity)\nstates = extract_states(connectivity)\n\n# Temporal part\nxt = exp(m * Symbol(\"t\"))\ny0 = Matrix([[Symbol(\"y0_A\"), Symbol(\"y0_B\"), 1 - Symbol(\"y0_A\") - Symbol(\"y0_B\")]]).T\n\n# Gaussian mixture model part\nmu = symbol_matrix(\"mu\", shape=(1, 3), suffix=states)\nsigma = symbol_matrix(\"sigma\", shape=(1, 3), suffix=states)\ngmm = GMM(Symbol(\"e\"), mu=mu, sigma=sigma)\n\nmodel = Model({Symbol(\"p\"): Mul(xt @ y0, gmm)})\n</pre> clear_symbols()  connectivity = [\"A &lt;-&gt; B -&gt; C\"] m = generate_transition_matrix(connectivity) states = extract_states(connectivity)  # Temporal part xt = exp(m * Symbol(\"t\")) y0 = Matrix([[Symbol(\"y0_A\"), Symbol(\"y0_B\"), 1 - Symbol(\"y0_A\") - Symbol(\"y0_B\")]]).T  # Gaussian mixture model part mu = symbol_matrix(\"mu\", shape=(1, 3), suffix=states) sigma = symbol_matrix(\"sigma\", shape=(1, 3), suffix=states) gmm = GMM(Symbol(\"e\"), mu=mu, sigma=sigma)  model = Model({Symbol(\"p\"): Mul(xt @ y0, gmm)}) In\u00a0[\u00a0]: Copied! <pre>parameters = model.define_parameters(guess_values)\n</pre> parameters = model.define_parameters(guess_values) In\u00a0[\u00a0]: Copied! <pre>parameters.set(\"y0_A\", lower_bound=0.0, upper_bound=1.0)  # mod? set_parameter ? modify?\nparameters.set(\"y0_B\", lower_bound=0.0, upper_bound=1.0, fixed=True)\n\nparameters.set(\"k_A_B\", lower_bound=1e-3, upper_bound=1e2)\nparameters.set(\"k_B_A\", lower_bound=1e-3, upper_bound=1e2)\nparameters.set(\"k_B_C\", lower_bound=1e-3, upper_bound=1e2)\n</pre> parameters.set(\"y0_A\", lower_bound=0.0, upper_bound=1.0)  # mod? set_parameter ? modify? parameters.set(\"y0_B\", lower_bound=0.0, upper_bound=1.0, fixed=True)  parameters.set(\"k_A_B\", lower_bound=1e-3, upper_bound=1e2) parameters.set(\"k_B_A\", lower_bound=1e-3, upper_bound=1e2) parameters.set(\"k_B_C\", lower_bound=1e-3, upper_bound=1e2) In\u00a0[\u00a0]: Copied! <pre># To calculate the likelihood for a measurement we need to sum the individual probabilities for all states\n# Thus we need to define which axis this is in the model\nSTATE_AXIS = 1\n</pre> # To calculate the likelihood for a measurement we need to sum the individual probabilities for all states # Thus we need to define which axis this is in the model STATE_AXIS = 1 In\u00a0[\u00a0]: Copied! <pre>fit = Fit(model, parameters, data, loss=LogSumLoss(sum_axis=STATE_AXIS))\nresult = fit.execute(\n    minimizer=LikelihoodOptimizer,\n    max_iter=200,\n    verbose=True,\n)\n</pre> fit = Fit(model, parameters, data, loss=LogSumLoss(sum_axis=STATE_AXIS)) result = fit.execute(     minimizer=LikelihoodOptimizer,     max_iter=200,     verbose=True, ) In\u00a0[\u00a0]: Copied! <pre>print(result)\n</pre> print(result) In\u00a0[\u00a0]: Copied! <pre>num = 100\nti = np.linspace(0, 11, num=num, endpoint=True)\nei = np.linspace(-0.1, 1.1, num=num, endpoint=True)\n\ngrid = np.meshgrid(ti, ei, sparse=True)\ngrid\n</pre>  num = 100 ti = np.linspace(0, 11, num=num, endpoint=True) ei = np.linspace(-0.1, 1.1, num=num, endpoint=True)  grid = np.meshgrid(ti, ei, sparse=True) grid In\u00a0[\u00a0]: Copied! <pre># since the `Mul` component of the model functions as a normal 'pyton' lazy multiplication,\n# we can make use of numpy broadcasting to evaluate the model on a 100x100 datapoint grid\n</pre> # since the `Mul` component of the model functions as a normal 'pyton' lazy multiplication, # we can make use of numpy broadcasting to evaluate the model on a 100x100 datapoint grid In\u00a0[\u00a0]: Copied! <pre># timing: 1.83 ms\ndata_eval = {\"t\": ti.reshape(-1, 1), \"e\": ei.reshape(-1, 1)}\nans = model(**result.parameters, **data_eval)\n</pre> # timing: 1.83 ms data_eval = {\"t\": ti.reshape(-1, 1), \"e\": ei.reshape(-1, 1)} ans = model(**result.parameters, **data_eval) In\u00a0[\u00a0]: Copied! <pre># output shape is (N, N, 3, 1), we sum and squeeze to create the NxN grid\narray = ans[\"p\"].sum(axis=-2).squeeze()\n</pre> # output shape is (N, N, 3, 1), we sum and squeeze to create the NxN grid array = ans[\"p\"].sum(axis=-2).squeeze() In\u00a0[\u00a0]: Copied! <pre>fig, ax = pplt.subplots()\nax.contour(ti, ei, array.T, cmap=\"viridis\", alpha=0.75)\nax.scatter(data[\"t\"], data[\"e\"], alpha=0.3, lw=0, color=\"k\", zorder=-10)\nax.format(xlabel=\"t\", ylabel=\"e\", title=\"GMM dynamics\")\npplt.show()\n</pre>  fig, ax = pplt.subplots() ax.contour(ti, ei, array.T, cmap=\"viridis\", alpha=0.75) ax.scatter(data[\"t\"], data[\"e\"], alpha=0.3, lw=0, color=\"k\", zorder=-10) ax.format(xlabel=\"t\", ylabel=\"e\", title=\"GMM dynamics\") pplt.show()"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>base</li> <li>fit</li> <li>fitresult</li> <li>functions</li> <li>loss</li> <li>markov</li> <li>minimizers</li> <li>models</li> <li>np_funcs</li> <li>numerical</li> <li>objective</li> <li>operations</li> <li>parameter</li> <li>reduce</li> <li>symbols</li> <li>typing</li> <li>utils</li> <li>v2<ul> <li>composite_expr</li> <li>expr</li> <li>loss</li> <li>minimize</li> <li>model</li> <li>parameter</li> <li>symbol</li> <li>typing</li> </ul> </li> </ul>"},{"location":"reference/base/","title":"base","text":""},{"location":"reference/base/#base.CompositeArgExpr","title":"<code>CompositeArgExpr</code>","text":"<p>               Bases: <code>CompositeExpr</code></p> <p>Composite expr which single args to init plus additional kwargs</p> Source code in <code>slimfit/base.py</code> <pre><code>class CompositeArgExpr(CompositeExpr):\n    \"\"\"Composite expr which single args to init plus additional kwargs\"\"\"\n\n    def __init__(self, arg, **kwargs):\n        expr = {0: arg}\n        self.kwargs = kwargs\n        super().__init__(expr)\n\n    def to_numerical(self):\n        from slimfit.numerical import to_numerical\n\n        arg = to_numerical(self.expr[0])\n        instance = self.__class__(arg, **self.kwargs)\n\n        return instance\n</code></pre>"},{"location":"reference/base/#base.CompositeArgsExpr","title":"<code>CompositeArgsExpr</code>","text":"<p>               Bases: <code>CompositeExpr</code></p> <p>Composite expr which takes *args to init rather than dictionary of expressions</p> Source code in <code>slimfit/base.py</code> <pre><code>class CompositeArgsExpr(CompositeExpr):\n    \"\"\"Composite expr which takes *args to init rather than dictionary of expressions\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        expr = {i: arg for i, arg in enumerate(args)}\n        self.kwargs = kwargs\n        super().__init__(expr)\n\n    def to_numerical(self):\n        from slimfit.numerical import to_numerical\n\n        args = (to_numerical(expr) for expr in self.values())\n        instance = self.__class__(*args, **self.kwargs)\n\n        return instance\n</code></pre>"},{"location":"reference/base/#base.CompositeExpr","title":"<code>CompositeExpr</code>","text":"<p>               Bases: <code>SymbolicBase</code></p> Source code in <code>slimfit/base.py</code> <pre><code>class CompositeExpr(SymbolicBase):\n    \"\"\"\"\"\"\n\n    def __init__(\n        self,\n        expr: dict[str | NumExprBase | Expr | CompositeExpr | MatrixBase | np.ndarray, float],\n    ):\n        if not isinstance(expr, dict):\n            raise TypeError(f\"{self.__class__.__name__} must be initialized with a dict.\")\n        # for v in expr.values():\n        #     if not isinstance(v, (NumExprBase, Expr, CompositeExpr, MatrixBase)):\n        #         raise TypeError(f\"Invalid type in expr dict: {v!r}.\")\n\n        self.expr = expr\n\n        if self.is_numerical():\n            self._call = self._numerical_call\n        else:\n            self._call = self._symbolic_call\n\n    def _numerical_call(self, **kwargs):\n        return {expr_name: expr(**kwargs) for expr_name, expr in self.expr.items()}\n\n    def _symbolic_call(self, **kwargs):\n        return self.numerical._call(**kwargs)\n\n    def __call__(self, **kwargs) -&gt; dict[str, np.ndarray]:\n        return self._call(**kwargs)\n\n    def __getitem__(self, item) -&gt; NumExprBase | Expr:\n        if isinstance(item, str):\n            return self.expr.__getitem__(item)\n        else:\n            return super().__getitem__(item)\n\n    def is_numerical(self) -&gt; bool:\n        \"\"\"Returns `True` if all expressions are numerical expressions.\"\"\"\n        for v in self.values():\n            # this should check for all base (non-composite) classes which are allowed and\n            # can be converted to numerical\n            # todo list this globally and check for this at init time\n            if isinstance(v, (Expr, MatrixBase, HadamardProduct, np.ndarray)):\n                return False\n            if isinstance(v, CompositeExpr):\n                # recursively check if composite parts are numerical\n                return v.is_numerical()\n        return True\n\n    @cached_property\n    def numerical(self) -&gt; Optional[CompositeExpr]:\n        if self.is_numerical():\n            return self\n        else:\n            return self.to_numerical()\n\n    def keys(self) -&gt; KeysView[str]:\n        return self.expr.keys()\n\n    def values(self) -&gt; ValuesView[NumExprBase, Expr]:\n        return self.expr.values()\n\n    def items(self) -&gt; ItemsView[str, NumExprBase, Expr]:\n        return self.expr.items()\n\n    def to_numerical(self):\n        from slimfit.numerical import to_numerical\n\n        num_expr = {str(k): to_numerical(expr) for k, expr in self.items()}\n\n        # TODO **unpack\n        instance = self.__class__(num_expr)\n        return instance\n\n    @cached_property\n    def symbols(self) -&gt; set[Symbol]:\n        \"\"\"Return symbols in the CompositeNumExpr.\n        sorting is by dependent_variables, variables, parameters, then by alphabet\n        \"\"\"\n\n        # this fails because `free_symbols` is a dict on NumExpr but `set` on Expr\n\n        symbols = set()\n        for rhs in self.values():\n            if isinstance(rhs, (Expr, MatrixBase)):\n                symbols |= rhs.free_symbols\n            else:\n                try:\n                    symbols |= set(rhs.symbols)\n                except AttributeError:\n                    # RHS doesnt have any symbols; for example might be a numpy array\n                    pass\n\n            # symbols = getattr(rhs, 'free_symbols')\n            # try:\n            #     # rhs is a sympy `Expr` and has `free_symbols` as a set\n            #     symbols |= rhs.free_symbols\n            # except TypeError:\n            #     # rhs is a slimfit `NumExpr`\n            #     symbols |= set(rhs.symbols)\n            # except AttributeError:\n            #     # RHS doesnt have any symbols; for example might be a numpy array\n            #     pass\n        return symbols\n\n    @property\n    def shapes(self) -&gt; dict[str, Shape]:\n        \"\"\"shapes of symbols\"\"\"\n        return reduce(or_(expr.shapes for expr in self.expr.values()))\n\n    @property\n    def shape(self) -&gt; Shape:\n        \"\"\"\n        Base class shape is obtained from broadcasting all expressing values together\n        \"\"\"\n        shapes = (expr.shape for expr in self.values())\n        return np.broadcast_shapes(*shapes)\n</code></pre>"},{"location":"reference/base/#base.CompositeExpr.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Base class shape is obtained from broadcasting all expressing values together</p>"},{"location":"reference/base/#base.CompositeExpr.shapes","title":"<code>shapes</code>  <code>property</code>","text":"<p>shapes of symbols</p>"},{"location":"reference/base/#base.CompositeExpr.symbols","title":"<code>symbols</code>  <code>cached</code> <code>property</code>","text":"<p>Return symbols in the CompositeNumExpr. sorting is by dependent_variables, variables, parameters, then by alphabet</p>"},{"location":"reference/base/#base.CompositeExpr.is_numerical","title":"<code>is_numerical()</code>","text":"<p>Returns <code>True</code> if all expressions are numerical expressions.</p> Source code in <code>slimfit/base.py</code> <pre><code>def is_numerical(self) -&gt; bool:\n    \"\"\"Returns `True` if all expressions are numerical expressions.\"\"\"\n    for v in self.values():\n        # this should check for all base (non-composite) classes which are allowed and\n        # can be converted to numerical\n        # todo list this globally and check for this at init time\n        if isinstance(v, (Expr, MatrixBase, HadamardProduct, np.ndarray)):\n            return False\n        if isinstance(v, CompositeExpr):\n            # recursively check if composite parts are numerical\n            return v.is_numerical()\n    return True\n</code></pre>"},{"location":"reference/base/#base.NumExprBase","title":"<code>NumExprBase</code>","text":"<p>               Bases: <code>SymbolicBase</code></p> <p>Symbolic expression which allows calling cached lambified expressions subclasses must implement <code>symbols</code> attribute / property</p> Source code in <code>slimfit/base.py</code> <pre><code>class NumExprBase(SymbolicBase):\n    \"\"\"Symbolic expression which allows calling cached lambified expressions\n    subclasses must implement `symbols` attribute / property\n    \"\"\"\n\n    # def __init__(\n    #     self,\n    # ):\n    #\n    #     # Accepted parameters are a subset of `symbols`\n    #     # #todo property with getter / setter where setter filters parameters?\n    #     # self.parameters = Parameters({name: p for name, p in parameters.items() if name in self.symbols})\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        for name in self.symbol_names:\n            if not is_valid_key(name):\n                raise ValueError(f\"Invalid symbol name: {name}; must be valid python identifier.\")\n\n    @property\n    def shape(self) -&gt; Shape:\n        shapes = self.shapes.values()\n\n        return np.broadcast_shapes(*shapes)\n\n    def parse_kwargs(self, **kwargs) -&gt; dict[str, np.ndarray]:\n        \"\"\"Parse kwargs and take only the ones in `free_parameters`\"\"\"\n        try:\n            arguments: dict[str, np.ndarray | float] = {k: kwargs[k] for k in self.symbol_names}\n        except KeyError as e:\n            raise KeyError(f\"Missing value for {e}\") from e\n\n        return arguments\n</code></pre>"},{"location":"reference/base/#base.NumExprBase.parse_kwargs","title":"<code>parse_kwargs(**kwargs)</code>","text":"<p>Parse kwargs and take only the ones in <code>free_parameters</code></p> Source code in <code>slimfit/base.py</code> <pre><code>def parse_kwargs(self, **kwargs) -&gt; dict[str, np.ndarray]:\n    \"\"\"Parse kwargs and take only the ones in `free_parameters`\"\"\"\n    try:\n        arguments: dict[str, np.ndarray | float] = {k: kwargs[k] for k in self.symbol_names}\n    except KeyError as e:\n        raise KeyError(f\"Missing value for {e}\") from e\n\n    return arguments\n</code></pre>"},{"location":"reference/base/#base.SymbolicBase","title":"<code>SymbolicBase</code>","text":"Source code in <code>slimfit/base.py</code> <pre><code>class SymbolicBase(metaclass=abc.ABCMeta):\n    @cached_property\n    @abc.abstractmethod\n    def symbols(self) -&gt; set[Symbol]:\n        ...\n\n    @cached_property\n    def symbol_names(self) -&gt; set[str]:\n        return set(s.name for s in self.symbols)\n\n    @property\n    def shapes(self) -&gt; dict[str, Shape]:\n        \"\"\"\n        dict of symbol shapes\n        \"\"\"\n\n    def filter_parameters(self, parameters: Parameters) -&gt; Parameters:\n        \"\"\"Filters a list of parameters, returning only the ones whose symbols are\n        in this model\n        \"\"\"\n        return Parameters([p for p in parameters if p.symbol in self.symbols])\n\n    @property\n    def T(self):\n        return FuncExpr(self, func=np.transpose)\n\n    def __getitem__(self, item):\n        from slimfit.operations import Indexer\n\n        return Indexer(self, item)\n</code></pre>"},{"location":"reference/base/#base.SymbolicBase.shapes","title":"<code>shapes</code>  <code>property</code>","text":"<p>dict of symbol shapes</p>"},{"location":"reference/base/#base.SymbolicBase.filter_parameters","title":"<code>filter_parameters(parameters)</code>","text":"<p>Filters a list of parameters, returning only the ones whose symbols are in this model</p> Source code in <code>slimfit/base.py</code> <pre><code>def filter_parameters(self, parameters: Parameters) -&gt; Parameters:\n    \"\"\"Filters a list of parameters, returning only the ones whose symbols are\n    in this model\n    \"\"\"\n    return Parameters([p for p in parameters if p.symbol in self.symbols])\n</code></pre>"},{"location":"reference/base/#base.is_valid_key","title":"<code>is_valid_key(key)</code>","text":"<p>Checks if a string is a valid key to use as keyword argument in a function call.</p> Source code in <code>slimfit/base.py</code> <pre><code>def is_valid_key(key: str) -&gt; bool:\n    \"\"\"Checks if a string is a valid key to use as keyword argument in a function call.\"\"\"\n    return key.isidentifier() and not keyword.iskeyword(key)\n</code></pre>"},{"location":"reference/fit/","title":"fit","text":""},{"location":"reference/fit/#fit.Fit","title":"<code>Fit</code>","text":"<p>Class for fitting a model to data.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>Model to fit.</p> required <code>parameters</code> <code>list[Parameter] | Parameters</code> <p>List or Parameters object of parameters to fit.</p> required <code>data</code> <code>dict[str | Expr, ArrayLike]</code> <p>Dictionary of data to fit to. Keys correspond to model symbols.</p> required <code>loss</code> <code>Optional[Loss]</code> <p>Loss function to use. Defaults to L2Loss.</p> <code>SELoss()</code> <p>Attributes:</p> Name Type Description <code>xdata</code> <p>Independent data, typically chosen measurement points.</p> <code>ydata</code> <p>Dependent data, typically measurements.</p> Source code in <code>slimfit/fit.py</code> <pre><code>class Fit:\n    \"\"\"\n    Class for fitting a model to data.\n\n    Args:\n        model: Model to fit.\n        parameters: List or Parameters object of parameters to fit.\n        data: Dictionary of data to fit to. Keys correspond to model symbols.\n        loss: Loss function to use. Defaults to L2Loss.\n\n    Attributes:\n        xdata: Independent data, typically chosen measurement points.\n        ydata: Dependent data, typically measurements.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Model,\n        parameters: list[Parameter] | Parameters,\n        data: dict[str | Expr, npt.ArrayLike],\n        loss: Optional[Loss] = SELoss(),\n    ) -&gt; None:\n        self.model = model\n\n        # make a new instance such that external modification does not affect the\n        # copy stored here\n        self.parameters = Parameters(parameters)\n\n        # Convert data keys to `str` if given as `Symbol; data values as arrays\n        data: dict[str, np.ndarray] = {\n            getattr(k, \"name\", k): np.asarray(v) for k, v in data.items()\n        }\n        self.loss = loss\n\n        # 'independent' data; or 'xdata'; typically chosen measurement points\n        self.xdata = {k: v for k, v in data.items() if k in self.model.symbol_names}\n\n        # 'dependent' data; or 'ydata'; typically measurements\n        self.ydata = {k: v for k, v in data.items() if k in self.model.dependent_symbols}\n\n    def execute(\n        self,\n        minimizer: Optional[Type[Minimizer]] = None,\n        **execute_options,\n    ) -&gt; FitResult:\n        \"\"\"\n        Execute the fit.\n\n        Args:\n            minimizer: Optional minimizer to use. Defaults to ScipyMinimizer.\n            **execute_options:\n\n        Returns:\n            Result of the fit as FitResult object.\n\n        \"\"\"\n\n        minimizer_cls = minimizer or self.get_minimizer()\n        minimizer_instance = minimizer_cls(\n            self.model, self.parameters, self.loss, self.xdata, self.ydata\n        )\n\n        result = minimizer_instance.execute(**execute_options)\n\n        result.minimizer = minimizer_instance\n\n        return result\n\n    def get_minimizer(self) -&gt; Type[Minimizer]:\n        \"\"\"Automatically determine which minimizer to use\"\"\"\n        return ScipyMinimizer\n\n    # def hessian(self, **parameters):\n    #     free_parameters = {p.name: p for p in parameters if not p.fixed}\n    #     fixed_parameters = {p.name: p for p in parameters if p.fixed}\n    #\n    #     if extra_parameters := parameters.keys() - free_parameters.keys():\n    #         raise ValueError(f\"Unknown parameters: {', '.join(extra_parameters)}\")\n    #     if missing_parameters := free_parameters.keys() - parameters.keys():\n    #         raise ValueError(f\"Missing parameters: {', '.join(missing_parameters)}\")\n    #\n    #     # but how do i know which hessian entries correspond to which parameters?\n\n    def get_loss(self, **kwargs):\n        raise NotImplementedError()\n        if self.model.probabilistic:\n            return LogLoss(**kwargs)\n        else:\n            return SELoss(**kwargs)\n</code></pre>"},{"location":"reference/fit/#fit.Fit.execute","title":"<code>execute(minimizer=None, **execute_options)</code>","text":"<p>Execute the fit.</p> <p>Parameters:</p> Name Type Description Default <code>minimizer</code> <code>Optional[Type[Minimizer]]</code> <p>Optional minimizer to use. Defaults to ScipyMinimizer.</p> <code>None</code> <code>**execute_options</code> <code>{}</code> <p>Returns:</p> Type Description <code>FitResult</code> <p>Result of the fit as FitResult object.</p> Source code in <code>slimfit/fit.py</code> <pre><code>def execute(\n    self,\n    minimizer: Optional[Type[Minimizer]] = None,\n    **execute_options,\n) -&gt; FitResult:\n    \"\"\"\n    Execute the fit.\n\n    Args:\n        minimizer: Optional minimizer to use. Defaults to ScipyMinimizer.\n        **execute_options:\n\n    Returns:\n        Result of the fit as FitResult object.\n\n    \"\"\"\n\n    minimizer_cls = minimizer or self.get_minimizer()\n    minimizer_instance = minimizer_cls(\n        self.model, self.parameters, self.loss, self.xdata, self.ydata\n    )\n\n    result = minimizer_instance.execute(**execute_options)\n\n    result.minimizer = minimizer_instance\n\n    return result\n</code></pre>"},{"location":"reference/fit/#fit.Fit.get_minimizer","title":"<code>get_minimizer()</code>","text":"<p>Automatically determine which minimizer to use</p> Source code in <code>slimfit/fit.py</code> <pre><code>def get_minimizer(self) -&gt; Type[Minimizer]:\n    \"\"\"Automatically determine which minimizer to use\"\"\"\n    return ScipyMinimizer\n</code></pre>"},{"location":"reference/fitresult/","title":"fitresult","text":""},{"location":"reference/fitresult/#fitresult.FitResult","title":"<code>FitResult</code>  <code>dataclass</code>","text":"<p>Fit result object.</p> Source code in <code>slimfit/fitresult.py</code> <pre><code>@dataclass\nclass FitResult:\n    \"\"\"\n    Fit result object.\n    \"\"\"\n\n    fit_parameters: dict[str, np.ndarray]\n    \"\"\"Fitted parameter values\"\"\"\n\n    gof_qualifiers: dict\n    \"\"\"Goodness-of-fit qualifiers\"\"\"\n\n    fixed_parameters: dict[str, float | np.ndarray] = field(default_factory=dict)  # Numerical dtype\n    \"\"\"Values of the model's fixed parameters\"\"\"\n\n    guess: Optional[dict] = None\n    \"\"\"Initial guesses\"\"\"\n\n    minimizer: Optional[Minimizer] = None\n\n    hessian: Optional[np.ndarray] = None\n\n    metadata: dict = field(default_factory=dict)\n    \"\"\"Additional metadata\"\"\"\n\n    base_result: Optional[Any] = field(default=None, repr=False)\n    \"\"\"Source fit result object. Can be dicts of sub results\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        if \"datetime\" not in self.metadata:\n            now = datetime.now()\n            self.metadata[\"datetime\"] = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n            self.metadata[\"timestamp\"] = int(now.timestamp())\n\n    def __str__(self):\n        if any(np.ndim(v) != 0 for v in self.fit_parameters.values()):\n            raise ValueError(\"Cannot print fit result with array values.\")\n\n        s = \"\"\n        stdev = self.stdev if self.hessian is not None else None\n\n        p_size = max(len(k) for k in self.fit_parameters)\n        if stdev:\n            s += f\"{'Parameter':&lt;{p_size}} {'Value':&gt;10} {'Stdev':&gt;10}\\n\"\n        else:\n            s += f\"{'Parameter':&lt;{p_size}} {'Value':&gt;10}\\n\"\n\n        for k, v in self.fit_parameters.items():\n            s += f\"{k:&lt;{max(p_size, 9)}} {v:&gt;10.3g}\"\n            if stdev:\n                s += f\" {stdev[k]:&gt;10.3g}\"\n            s += \"\\n\"\n\n        return s\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"\n        Convert the fit result to a dictionary.\n\n        Returns:\n            Dictionary representation of the fit result.\n        \"\"\"\n        keys = [\n            \"gof_qualifiers\",\n            \"fit_parameters\",\n            \"fixed_parameters\",\n            \"guess\",\n            \"metadata\",\n        ]\n        if self.hessian is not None:\n            keys += [\"stdev\"]\n\n        d = {k: v for k in keys if (v := getattr(self, k)) is not None}\n\n        return clean_types(d)\n\n    def to_yaml(self, path: Union[os.PathLike[str], str], sort_keys: bool = False) -&gt; None:\n        \"\"\"\n        Save the fit result as yaml.\n\n        Args:\n            path: Path to save to.\n            sort_keys: Boolean indicating whether to sort the keys.\n\n        \"\"\"\n        Path(path).write_text(yaml.dump(self.to_dict(), sort_keys=sort_keys))\n\n    def to_pickle(self, path: Union[os.PathLike[str], str]) -&gt; None:\n        \"\"\"\n        Save the fit result as pickle.\n\n        Args:\n            path: Path to save to.\n        \"\"\"\n        try:\n            del self.minimizer.model.numerical\n        except AttributeError:\n            pass\n\n        with Path(path).open(\"wb\") as f:\n            pickle.dump(self, f)\n\n    def eval_hessian(self, hessian: Optional[Hessian] = None) -&gt; np.ndarray:\n        # TODO Hessian as parameter / strategy\n        \"\"\"Evaluate the hessian at the fitted parameters values\"\"\"\n\n        hessian = hessian or rgetattr(self.minimizer, \"objective.hessian\", None)\n        if hessian is None:\n            raise ValueError(\"No Hessian available\")\n\n        if hasattr(self.minimizer, \"objective\") and list(hessian.shapes.items()) != list(\n            self.minimizer.objective.shapes.items()\n        ):\n            raise ValueError(\"Mismatch between objective and fit parameters\")\n\n        x = pack(self.fit_parameters.values())\n        self.hessian = hessian(x)\n\n        return self.hessian\n\n    @property\n    def variance(self) -&gt; dict[str, float | np.ndarray]:\n        if self.hessian is None:\n            self.eval_hessian()\n\n        hess_inv = np.linalg.inv(self.hessian)\n        var = np.diag(hess_inv)\n        parameter_shapes = {k: v.shape for k, v in self.fit_parameters.items()}\n        return unpack(var, parameter_shapes)\n\n    @property\n    def stdev(self) -&gt; dict[str, float | np.ndarray]:\n        return {k: np.sqrt(v) for k, v in self.variance.items()}\n\n    @property\n    def parameters(self) -&gt; dict[str, float | np.ndarray]:\n        return {**self.fit_parameters, **self.fixed_parameters}\n</code></pre>"},{"location":"reference/fitresult/#fitresult.FitResult.base_result","title":"<code>base_result = field(default=None, repr=False)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Source fit result object. Can be dicts of sub results</p>"},{"location":"reference/fitresult/#fitresult.FitResult.fit_parameters","title":"<code>fit_parameters</code>  <code>instance-attribute</code>","text":"<p>Fitted parameter values</p>"},{"location":"reference/fitresult/#fitresult.FitResult.fixed_parameters","title":"<code>fixed_parameters = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Values of the model's fixed parameters</p>"},{"location":"reference/fitresult/#fitresult.FitResult.gof_qualifiers","title":"<code>gof_qualifiers</code>  <code>instance-attribute</code>","text":"<p>Goodness-of-fit qualifiers</p>"},{"location":"reference/fitresult/#fitresult.FitResult.guess","title":"<code>guess = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Initial guesses</p>"},{"location":"reference/fitresult/#fitresult.FitResult.metadata","title":"<code>metadata = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Additional metadata</p>"},{"location":"reference/fitresult/#fitresult.FitResult.eval_hessian","title":"<code>eval_hessian(hessian=None)</code>","text":"<p>Evaluate the hessian at the fitted parameters values</p> Source code in <code>slimfit/fitresult.py</code> <pre><code>def eval_hessian(self, hessian: Optional[Hessian] = None) -&gt; np.ndarray:\n    # TODO Hessian as parameter / strategy\n    \"\"\"Evaluate the hessian at the fitted parameters values\"\"\"\n\n    hessian = hessian or rgetattr(self.minimizer, \"objective.hessian\", None)\n    if hessian is None:\n        raise ValueError(\"No Hessian available\")\n\n    if hasattr(self.minimizer, \"objective\") and list(hessian.shapes.items()) != list(\n        self.minimizer.objective.shapes.items()\n    ):\n        raise ValueError(\"Mismatch between objective and fit parameters\")\n\n    x = pack(self.fit_parameters.values())\n    self.hessian = hessian(x)\n\n    return self.hessian\n</code></pre>"},{"location":"reference/fitresult/#fitresult.FitResult.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the fit result to a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation of the fit result.</p> Source code in <code>slimfit/fitresult.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"\n    Convert the fit result to a dictionary.\n\n    Returns:\n        Dictionary representation of the fit result.\n    \"\"\"\n    keys = [\n        \"gof_qualifiers\",\n        \"fit_parameters\",\n        \"fixed_parameters\",\n        \"guess\",\n        \"metadata\",\n    ]\n    if self.hessian is not None:\n        keys += [\"stdev\"]\n\n    d = {k: v for k in keys if (v := getattr(self, k)) is not None}\n\n    return clean_types(d)\n</code></pre>"},{"location":"reference/fitresult/#fitresult.FitResult.to_pickle","title":"<code>to_pickle(path)</code>","text":"<p>Save the fit result as pickle.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[PathLike[str], str]</code> <p>Path to save to.</p> required Source code in <code>slimfit/fitresult.py</code> <pre><code>def to_pickle(self, path: Union[os.PathLike[str], str]) -&gt; None:\n    \"\"\"\n    Save the fit result as pickle.\n\n    Args:\n        path: Path to save to.\n    \"\"\"\n    try:\n        del self.minimizer.model.numerical\n    except AttributeError:\n        pass\n\n    with Path(path).open(\"wb\") as f:\n        pickle.dump(self, f)\n</code></pre>"},{"location":"reference/fitresult/#fitresult.FitResult.to_yaml","title":"<code>to_yaml(path, sort_keys=False)</code>","text":"<p>Save the fit result as yaml.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[PathLike[str], str]</code> <p>Path to save to.</p> required <code>sort_keys</code> <code>bool</code> <p>Boolean indicating whether to sort the keys.</p> <code>False</code> Source code in <code>slimfit/fitresult.py</code> <pre><code>def to_yaml(self, path: Union[os.PathLike[str], str], sort_keys: bool = False) -&gt; None:\n    \"\"\"\n    Save the fit result as yaml.\n\n    Args:\n        path: Path to save to.\n        sort_keys: Boolean indicating whether to sort the keys.\n\n    \"\"\"\n    Path(path).write_text(yaml.dump(self.to_dict(), sort_keys=sort_keys))\n</code></pre>"},{"location":"reference/functions/","title":"functions","text":""},{"location":"reference/functions/#functions.gaussian_matrix","title":"<code>gaussian_matrix(x, mu, sigma)</code>","text":"<p>Applies gaussian function elementwise from a 'mu' and 'sigma' matrix; given a variable 'x'</p> Source code in <code>slimfit/functions.py</code> <pre><code>def gaussian_matrix(x: Variable, mu: Matrix, sigma: Matrix) -&gt; Matrix:\n    \"\"\"Applies gaussian function elementwise from a 'mu' and 'sigma' matrix; given a variable 'x'\"\"\"\n    if mu.shape != sigma.shape:\n        raise ValueError(\"Shape mismatch between 'mu' and 'sigma'\")\n\n    m_out = zeros(*mu.shape)\n    for i, j in np.ndindex(mu.shape):\n        m_out[i, j] = gaussian_sympy(x, mu[i, j], sigma[i, j])\n\n    return m_out\n</code></pre>"},{"location":"reference/loss/","title":"loss","text":""},{"location":"reference/loss/#loss.L1Loss","title":"<code>L1Loss</code>","text":"<p>               Bases: <code>Loss</code></p> <p>L1 loss</p> Source code in <code>slimfit/loss.py</code> <pre><code>class L1Loss(Loss):\n    \"\"\"L1 loss\"\"\"\n\n    # todo refactor ydata / ymodel?\n    def __call__(\n        self, dependent_data: dict[str, np.ndarray], target_data: dict[str, np.ndarray]\n    ) -&gt; np.ndarray | float:\n        if self.weights is None:\n            residuals = {k: (target_data[k] - dependent_data[k]) for k in target_data.keys()}\n        else:\n            residuals = {\n                k: (target_data[k] - dependent_data[k]) * self.weights[k]\n                for k in target_data.keys()\n            }\n\n        return self.reduce(residuals)\n</code></pre>"},{"location":"reference/loss/#loss.LogLoss","title":"<code>LogLoss</code>","text":"<p>               Bases: <code>Loss</code></p> <p>Takes the elementwise logarithm of predicted input data</p> <p>Used in combination with maximum likelihood methods</p> <p>returns negative of the reductions are use in combination with minimizers rather than maximizers</p>"},{"location":"reference/loss/#loss.LogLoss--todo-move-minus-sign-to-objective","title":"TODO move minus sign to objective","text":"Source code in <code>slimfit/loss.py</code> <pre><code>class LogLoss(Loss):\n    \"\"\"Takes the elementwise logarithm of predicted input data\n\n    Used in combination with maximum likelihood methods\n\n    returns negative of the reductions are use in combination with minimizers rather than maximizers\n    #TODO move minus sign to objective\n    \"\"\"\n\n    def __init__(\n        self,\n        weights: Optional[dict[str, npt.ArrayLike]] = None,\n        reduction: Literal[\"mean\", \"sum\", \"concat\"] = \"sum\",\n    ):\n        if reduction not in [\"mean\", \"sum\", \"concat\"]:\n            raise ValueError(\n                f\"LogLoss does not support reduction {reduction!r}, only 'mean', 'sum', 'concat'\"\n            )\n        super().__init__(weights, reduction)\n\n    def __call__(\n        self, y_data: dict[str, np.ndarray], y_model: dict[str, np.ndarray]\n    ) -&gt; np.ndarray | float:\n        if self.weights is None:\n            # log_vals = {k: np.log(y_model[k]) for k in y_model.keys()}\n            log_vals = {\n                k: np.log(np.clip(y_model[k], a_min=MIN_PROB, a_max=None)) for k in y_model.keys()\n            }\n\n        else:\n            log_vals = {k: np.log(y_model[k] * self.weights[k]) for k in y_model.keys()}\n\n        return -self.reduce(log_vals)\n</code></pre>"},{"location":"reference/loss/#loss.LogSumLoss","title":"<code>LogSumLoss</code>","text":"<p>               Bases: <code>Loss</code></p> <p>Sums by specified axis, then takes elementwise log, then applies reduction method</p> <p>Used in combination with maximum likelihood methods</p> Example <p>returns negative of the reductions are use in combination with minimizers rather than maximizers</p> Source code in <code>slimfit/loss.py</code> <pre><code>class LogSumLoss(Loss):\n    \"\"\"Sums by specified axis, then takes elementwise log, then applies reduction method\n\n\n\n    Used in combination with maximum likelihood methods\n\n    Example:\n        # sum along axis 1, then takes elementwise log, then sums the result\n        LogSumLoss(sum_axis=1, reduction='sum')\n\n    returns negative of the reductions are use in combination with minimizers rather than maximizers\n    \"\"\"\n\n    def __init__(\n        self,\n        weights: Optional[dict[str, npt.ArrayLike]] = None,\n        sum_axis: Optional[int] = 1,\n        reduction: Literal[\"mean\", \"sum\", \"concat\"] = \"sum\",\n    ):\n        self.sum_axis = sum_axis\n        if reduction not in [\"mean\", \"sum\", \"concat\"]:\n            raise ValueError(\n                f\"LogSumLoss does not support reduction {reduction!r}, only 'mean', 'sum', 'concat'\"\n            )\n        super().__init__(weights, reduction)\n\n    def __call__(\n        self, y_data: dict[str, np.ndarray], y_model: dict[str, np.ndarray]\n    ) -&gt; np.ndarray | float:\n        # from slimfit.minimizer import MIN_PROB\n        if self.weights is None:\n            log_vals = {\n                k: np.log(\n                    # y_model[k].sum(axis=self.sum_axis),\n                    np.clip(y_model[k].sum(axis=self.sum_axis), a_min=MIN_PROB, a_max=None)\n                )\n                for k in y_model.keys()\n            }\n\n        else:\n            log_vals = {\n                k: np.log(\n                    # np.clip(y_model[k].sum(axis=self.sum_axis)) * self.weights[k], a_min=MIN_PROB, a_max=None)\n                    y_model[k].sum(axis=self.sum_axis)\n                    * self.weights[k]\n                )\n                for k in y_model.keys()\n            }\n\n        return -self.reduce(log_vals)\n</code></pre>"},{"location":"reference/loss/#loss.LogSumLoss--sum-along-axis-1-then-takes-elementwise-log-then-sums-the-result","title":"sum along axis 1, then takes elementwise log, then sums the result","text":"<p>LogSumLoss(sum_axis=1, reduction='sum')</p>"},{"location":"reference/loss/#loss.Loss","title":"<code>Loss</code>","text":"<p>               Bases: <code>object</code></p> <p>Loss function base class.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Optional[dict[str, ArrayLike]]</code> <p>Optional dictionary of weights for each data point. Must match <code>ydata</code> in shape.</p> <code>None</code> <code>reduction</code> <code>Literal['mean', 'sum', 'concat', 'none', None]</code> <p>Reduction strategy to use. Defaults to \"mean\".</p> <code>'sum'</code> <p>Attributes:</p> Name Type Description <code>reduce</code> <code>ReductionStrategy</code> <p>Callable that reduces the loss values.</p> Source code in <code>slimfit/loss.py</code> <pre><code>class Loss(object):\n    \"\"\"\n    Loss function base class.\n\n    Args:\n        weights: Optional dictionary of weights for each data point. Must match `ydata` in shape.\n        reduction: Reduction strategy to use. Defaults to \"mean\".\n\n    Attributes:\n        reduce: Callable that reduces the loss values.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        weights: Optional[dict[str, npt.ArrayLike]] = None,\n        reduction: Literal[\"mean\", \"sum\", \"concat\", \"none\", None] = \"sum\",\n    ):\n        self.weights = weights\n        if reduction == \"mean\":\n            self.reduce: ReductionStrategy = mean_reduction\n        elif reduction == \"sum\":\n            self.reduce: ReductionStrategy = sum_reduction\n        elif reduction == \"concat\":\n            self.reduce: ReductionStrategy = concat_reduction\n        elif reduction in [None, \"none\"]:\n            self.reduce = lambda x: x\n\n    @abc.abstractmethod\n    def __call__(\n        self, y_data: dict[str, np.ndarray], y_model: dict[str, np.ndarray]\n    ) -&gt; np.ndarray | float:\n        ...\n</code></pre>"},{"location":"reference/loss/#loss.SELoss","title":"<code>SELoss</code>","text":"<p>               Bases: <code>Loss</code></p> <p>Squared error loss</p> Source code in <code>slimfit/loss.py</code> <pre><code>class SELoss(Loss):\n    \"\"\"Squared error loss\"\"\"\n\n    def __call__(\n        self, y_data: dict[str, np.ndarray], y_model: dict[str, np.ndarray]\n    ) -&gt; np.ndarray | float:\n        if self.weights is None:\n            residuals = {k: (y_model[k] - y_data[k]) ** 2 for k in y_model.keys()}\n        else:\n            residuals = {\n                k: ((y_model[k] - y_data[k]) * self.weights[k]) ** 2 for k in y_model.keys()\n            }\n\n        return self.reduce(residuals)\n</code></pre>"},{"location":"reference/markov/","title":"markov","text":""},{"location":"reference/markov/#markov.exp_elements","title":"<code>exp_elements(m, base=10, sub_name=lambda x: 'u' + x[1:])</code>","text":"<p>Exponentiate elements of matrix to a given base, and optionally substitute parameters with new parameters</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>Matrix</code> <p>Input matrix which elements to exponentiate.</p> required <code>base</code> <p>Base of the exponent.</p> <code>10</code> <code>sub_name</code> <code>Optional[Callable]</code> <p>Function which takes parameter name and returns substitute parameter name.</p> <code>lambda x: 'u' + x[1:]</code> <p>Returns:</p> Type Description <code>Matrix</code> <p>Exponentiated matrix</p> Source code in <code>slimfit/markov.py</code> <pre><code>def exp_elements(\n    m: Matrix, base=10, sub_name: Optional[Callable] = lambda x: \"u\" + x[1:]\n) -&gt; Matrix:\n    \"\"\"\n    Exponentiate elements of matrix to a given base, and optionally substitute parameters with new parameters\n\n    Args:\n        m: Input matrix which elements to exponentiate.\n        base: Base of the exponent.\n        sub_name: Function which takes parameter name and returns substitute parameter name.\n\n    Returns:\n        Exponentiated matrix\n\n    \"\"\"\n    out = zeros(*m.shape)\n    for i, j in np.ndindex(m.shape):\n        elem = m[i, j]\n        if elem == 0.0:\n            continue\n        else:\n            out[i, j] = base**elem\n\n    if sub_name is not None:\n        subs = [(p, Parameter(name=sub_name(p.name))) for p in t.free_symbols]\n        out = out.subs(subs)\n\n    return out\n</code></pre>"},{"location":"reference/markov/#markov.extract_states","title":"<code>extract_states(connectivity)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>connectivity</code> <code>list[str]</code> <p>List of reaction equations.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of states found in all reaction equations.</p> Source code in <code>slimfit/markov.py</code> <pre><code>def extract_states(connectivity: list[str]) -&gt; list[str]:\n    \"\"\"\n    Args:\n        connectivity: List of reaction equations.\n\n    Returns:\n        List of states found in all reaction equations.\n\n    \"\"\"\n\n    # extract states from connectivity list\n    all_states = [\n        s for s in reduce(add, [eqn.split(\" \") for eqn in connectivity]) if s not in OPERATORS\n    ]\n\n    # Remove duplicates, keep order\n    all_states = list(dict.fromkeys(all_states))\n\n    return all_states\n</code></pre>"},{"location":"reference/minimizers/","title":"minimizers","text":""},{"location":"reference/minimizers/#minimizers.ConstantOptimizer","title":"<code>ConstantOptimizer</code>","text":"<p>               Bases: <code>EMOptimizer</code></p> <p>model is of form {Probability(px): Matrix[[]] ...} where all matrix elements are just scalar parameters. Source code in <code>slimfit/minimizers.py</code> <pre><code>class ConstantOptimizer(EMOptimizer):\n\n    \"\"\"\n    model is of form {Probability(px): Matrix[[&lt;parameters&gt;]] ...} where all matrix elements are just scalar parameters.\n    \"\"\"\n\n    def step(self) -&gt; dict[str, float]:\n        parameters = {}\n        # for p_name in self.model.free_parameters:\n        for parameter in self.free_parameters:\n            num, denom = 0.0, 0.0\n            for lhs, rhs in self.model.items():\n                # rhs is of type MatrixNumExpr\n                if parameter.symbol in rhs.symbols:\n                    # Shapes of RHS matrices is (N_states, 1), find index with .index(name)\n                    state_index, _ = rhs.index(parameter.symbol)\n                    T_i = np.take(self.posterior[str(lhs)], state_index, axis=STATE_AXIS)\n                    num_i, denom_i = T_i.sum(), T_i.size\n\n                    num += num_i\n                    denom += denom_i\n            parameters[parameter.name] = num / denom\n\n        return parameters\n</code></pre>"},{"location":"reference/minimizers/#minimizers.GMMOptimizer","title":"<code>GMMOptimizer</code>","text":"<p>               Bases: <code>EMOptimizer</code></p> <p>optimizes parameter values of GMM (sub) model doesnt use guess directly but instead finds next values for parmater from posterior probabilities</p> <p>rhs of model should all be GMM CompositeNumExprs</p> Source code in <code>slimfit/minimizers.py</code> <pre><code>class GMMOptimizer(EMOptimizer):\n    \"\"\"optimizes parameter values of GMM (sub) model\n    doesnt use guess directly but instead finds next values for parmater from posterior probabilities\n\n    rhs of model should all be GMM CompositeNumExprs\n\n    \"\"\"\n\n    # TODO create `step` method which only does one step', execute should be full loop\n\n    def step(self) -&gt; dict[str, float]:\n        parameters = {}  # output parameters dictionary\n\n        # All symbols in all 'mu' expressions, then take intersection\n        mu_symbols = set.union(*(rhs[\"mu\"].symbols for rhs in self.model.values()))\n        mu_symbols &amp;= self.free_parameters.symbols\n\n        # take only the mu symbos in the set of symbols designated as parameters\n        mu_parameters = mu_symbols\n        # mu_parameters = reduce(\n        #     or_, [rhs[\"mu\"].free_parameters.keys() for rhs in self.model.values()]\n        # )\n        for mu_symbol in mu_parameters:\n            num, denom = 0.0, 0.0\n            for lhs, gmm_rhs in self.model.items():\n                # check if the current mu parameter in this GMM\n                if mu_symbol in gmm_rhs[\"mu\"].symbols:\n                    col, state_index = gmm_rhs[\"mu\"].index(mu_symbol)\n                    T_i = np.take(self.posterior[str(lhs)], state_index, axis=STATE_AXIS)\n\n                    # independent data should be given in the same shape as T_i\n                    # which is typically (N, 1), to be sure shapes match we reshape independent data\n                    # data = self.xdata[gmm_rhs['x'].name]\n                    num += np.sum(T_i * self.xdata[gmm_rhs[\"x\"].name].reshape(T_i.shape))\n                    denom += np.sum(T_i)\n\n            parameters[mu_symbol.name] = num / denom\n\n        sigma_symbols = set.union(*(rhs[\"sigma\"].symbols for rhs in self.model.values()))\n        sigma_symbols &amp;= self.free_parameters.symbols\n\n        # sigma_parameters = reduce(\n        #     or_, [rhs[\"sigma\"].free_parameters.keys() for rhs in self.model.values()]\n        # )\n        for sigma_symbol in sigma_symbols:\n            num, denom = 0.0, 0.0\n            # LHS in numerical models are `str` (at the moment)\n            for lhs, gmm_rhs in self.model.items():\n                # check if the current sigma parameter in this GMM\n                if sigma_symbol in gmm_rhs[\"sigma\"].symbols:\n                    col, state_index = gmm_rhs[\"sigma\"].index(sigma_symbol)\n\n                    T_i = np.take(self.posterior[str(lhs)], state_index, axis=STATE_AXIS)\n\n                    # Indexing of the MatrixExpr returns elements of its expr\n                    mu_name: str = gmm_rhs[\"mu\"][col, state_index].name\n\n                    # Take the corresponding value from the current parameters dict, if its not\n                    # there, it must be in the fixed parameters of the model\n                    try:\n                        mu_value = parameters[mu_name]\n                    except KeyError:\n                        mu_value = self.fixed_parameters.guess[mu_name]\n\n                    num += np.sum(\n                        T_i * (self.xdata[gmm_rhs[\"x\"].name].reshape(T_i.shape) - mu_value) ** 2\n                    )\n\n                    denom += np.sum(T_i)\n\n            parameters[sigma_symbol.name] = np.sqrt(num / denom)\n\n        return parameters\n</code></pre>"},{"location":"reference/minimizers/#minimizers.LikelihoodOptimizer","title":"<code>LikelihoodOptimizer</code>","text":"<p>               Bases: <code>Minimizer</code></p> <p>Assumed <code>loss</code> is <code>LogLoss</code></p> Source code in <code>slimfit/minimizers.py</code> <pre><code>class LikelihoodOptimizer(Minimizer):\n    \"\"\"\n    Assumed `loss` is `LogLoss`\n\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        if not isinstance(self.loss, LogSumLoss):\n            warnings.warn(\"Using non-log loss in likelihood optimizer\")\n        param_shapes = {p.name: p.shape for p in self.free_parameters}\n        # TODO rename and generalize?\n        self.objective = ScipyObjective(\n            model=self.model.numerical,\n            loss=self.loss,\n            xdata=self.xdata | self.fixed_parameters.guess,\n            ydata=self.ydata,\n            shapes=param_shapes,\n        )\n\n    def execute(\n        self, max_iter=250, patience=5, stop_loss=1e-7, verbose=True, **kwargs\n    ) -&gt; FitResult:\n        \"\"\"\n        kwargs: additional kwargs for scipy minimizer part\n\n        \"\"\"\n\n        # parameters which needs to be passed / inferred\n        # Split top-level multiplications in the model as they can be optimized in log likelihood independently\n        # TODO model should have this as property / method\n        components: list[tuple[Symbol, NumExprBase]] = []  # todo tuple LHS as variable\n        for lhs, rhs in self.model.numerical.items():\n            if isinstance(rhs, Mul):\n                components += [(lhs, elem) for elem in rhs.values()]\n            else:\n                components.append((lhs, rhs))\n\n        # Find the sets of components which have common parameters and thus need to be optimized together\n        sub_models = intersecting_component_symbols(components, self.free_parameters.symbols)\n\n        # Remove sub models without symbols\n        sub_models = [m for m in sub_models if m.symbols]\n\n        pbar = trange(max_iter, disable=not verbose)\n        t0 = time.time()\n\n        parameters_current = self.free_parameters.guess  # initialize parameters\n        prev_loss = 0.0\n        no_progress = 0\n        base_result = {}\n        for i in pbar:\n            y_model = self.model(**parameters_current, **self.xdata, **self.fixed_parameters.guess)\n            loss = self.loss(self.ydata, y_model)\n\n            # posterior dict has values with shapes equal to y_model\n            # which is (dataopints, states, 1)\n            posterior = {k: v / v.sum(axis=STATE_AXIS, keepdims=True) for k, v in y_model.items()}\n\n            # dictionary of new parameter values for in this iteration\n            parameters_step = {}\n            common_kwargs = dict(\n                loss=self.loss,\n                xdata=self.xdata,\n                ydata=self.ydata,\n                posterior=posterior,\n            )\n            for sub_model in sub_models:\n                # At the moment we assume all callables in the sub models to be MatrixCallables\n                # determine the kind\n                kinds = [getattr(c, \"kind\", None) for c in sub_model.values()]\n                # Filter the general list of parameters to reduce it down to the parameters\n                # this model accepts\n                # the sub model also needs to the fixed parameters to correctly be able to\n                # call the model; GMM also needs it for finding sigma\n                sub_parameters = sub_model.filter_parameters(self.parameters)\n                if all(k == \"constant\" for k in kinds):\n                    # Constant optimizer doesnt use loss, xdata, ydata,\n                    opt = ConstantOptimizer(sub_model, sub_parameters, **common_kwargs)\n                    parameters = opt.step()\n                elif all(k == \"gmm\" for k in kinds) and not sub_parameters.has_bounds:\n                    # Loss is not used for GMM optimizer step\n                    opt = GMMOptimizer(sub_model, sub_parameters, **common_kwargs)\n                    parameters = opt.step()\n                else:\n                    # Previous code:\n                    # updated_parameters = [\n                    #     Parameter(**(asdict(p) | {\"guess\": parameters_current.get(p.name) or self.fixed_parameters.guess[p.name]  }))\n                    #     for p in sub_parameters\n                    # ]\n\n                    # New; needs improvement as it accesses `_names`\n                    current_sub = {\n                        k: v for k, v in parameters_current.items() if k in sub_parameters._names\n                    }\n                    updated_parameters = sub_parameters.update_guess(current_sub)\n\n                    # todo loss is not used; should be EM loss while the main loop uses Log likelihood loss\n                    opt = ScipyEMOptimizer(sub_model, updated_parameters, **common_kwargs)\n\n                    scipy_result = opt.execute(**kwargs)\n                    parameters = scipy_result.fit_parameters\n                    base_result[\"scipy\"] = scipy_result\n\n                # collect parameters of this sub_model into parameters dict\n                parameters_step |= parameters\n\n            # update for next iteration\n            parameters_current = parameters_step\n\n            # loss\n            improvement = prev_loss - loss\n            prev_loss = loss\n            pbar.set_postfix({\"improvement\": improvement})\n\n            if np.isnan(improvement):\n                break\n            elif improvement &lt; stop_loss:\n                no_progress += 1\n            else:\n                no_progress = 0\n\n            if no_progress &gt; patience:\n                break\n\n        tdelta = time.time() - t0\n        gof_qualifiers = {\n            \"loss\": loss,\n            \"log_likelihood\": -loss,\n            \"n_iter\": i + 1,\n            \"elapsed\": tdelta,\n            \"iter/s\": (i + 1) / tdelta,\n        }\n\n        result = FitResult(\n            fit_parameters=parameters_current,\n            fixed_parameters=self.fixed_parameters.guess,\n            gof_qualifiers=gof_qualifiers,\n            guess=self.free_parameters.guess,\n            base_result=base_result,\n        )\n\n        return result\n</code></pre>"},{"location":"reference/minimizers/#minimizers.LikelihoodOptimizer.execute","title":"<code>execute(max_iter=250, patience=5, stop_loss=1e-07, verbose=True, **kwargs)</code>","text":"<p>kwargs: additional kwargs for scipy minimizer part</p> Source code in <code>slimfit/minimizers.py</code> <pre><code>def execute(\n    self, max_iter=250, patience=5, stop_loss=1e-7, verbose=True, **kwargs\n) -&gt; FitResult:\n    \"\"\"\n    kwargs: additional kwargs for scipy minimizer part\n\n    \"\"\"\n\n    # parameters which needs to be passed / inferred\n    # Split top-level multiplications in the model as they can be optimized in log likelihood independently\n    # TODO model should have this as property / method\n    components: list[tuple[Symbol, NumExprBase]] = []  # todo tuple LHS as variable\n    for lhs, rhs in self.model.numerical.items():\n        if isinstance(rhs, Mul):\n            components += [(lhs, elem) for elem in rhs.values()]\n        else:\n            components.append((lhs, rhs))\n\n    # Find the sets of components which have common parameters and thus need to be optimized together\n    sub_models = intersecting_component_symbols(components, self.free_parameters.symbols)\n\n    # Remove sub models without symbols\n    sub_models = [m for m in sub_models if m.symbols]\n\n    pbar = trange(max_iter, disable=not verbose)\n    t0 = time.time()\n\n    parameters_current = self.free_parameters.guess  # initialize parameters\n    prev_loss = 0.0\n    no_progress = 0\n    base_result = {}\n    for i in pbar:\n        y_model = self.model(**parameters_current, **self.xdata, **self.fixed_parameters.guess)\n        loss = self.loss(self.ydata, y_model)\n\n        # posterior dict has values with shapes equal to y_model\n        # which is (dataopints, states, 1)\n        posterior = {k: v / v.sum(axis=STATE_AXIS, keepdims=True) for k, v in y_model.items()}\n\n        # dictionary of new parameter values for in this iteration\n        parameters_step = {}\n        common_kwargs = dict(\n            loss=self.loss,\n            xdata=self.xdata,\n            ydata=self.ydata,\n            posterior=posterior,\n        )\n        for sub_model in sub_models:\n            # At the moment we assume all callables in the sub models to be MatrixCallables\n            # determine the kind\n            kinds = [getattr(c, \"kind\", None) for c in sub_model.values()]\n            # Filter the general list of parameters to reduce it down to the parameters\n            # this model accepts\n            # the sub model also needs to the fixed parameters to correctly be able to\n            # call the model; GMM also needs it for finding sigma\n            sub_parameters = sub_model.filter_parameters(self.parameters)\n            if all(k == \"constant\" for k in kinds):\n                # Constant optimizer doesnt use loss, xdata, ydata,\n                opt = ConstantOptimizer(sub_model, sub_parameters, **common_kwargs)\n                parameters = opt.step()\n            elif all(k == \"gmm\" for k in kinds) and not sub_parameters.has_bounds:\n                # Loss is not used for GMM optimizer step\n                opt = GMMOptimizer(sub_model, sub_parameters, **common_kwargs)\n                parameters = opt.step()\n            else:\n                # Previous code:\n                # updated_parameters = [\n                #     Parameter(**(asdict(p) | {\"guess\": parameters_current.get(p.name) or self.fixed_parameters.guess[p.name]  }))\n                #     for p in sub_parameters\n                # ]\n\n                # New; needs improvement as it accesses `_names`\n                current_sub = {\n                    k: v for k, v in parameters_current.items() if k in sub_parameters._names\n                }\n                updated_parameters = sub_parameters.update_guess(current_sub)\n\n                # todo loss is not used; should be EM loss while the main loop uses Log likelihood loss\n                opt = ScipyEMOptimizer(sub_model, updated_parameters, **common_kwargs)\n\n                scipy_result = opt.execute(**kwargs)\n                parameters = scipy_result.fit_parameters\n                base_result[\"scipy\"] = scipy_result\n\n            # collect parameters of this sub_model into parameters dict\n            parameters_step |= parameters\n\n        # update for next iteration\n        parameters_current = parameters_step\n\n        # loss\n        improvement = prev_loss - loss\n        prev_loss = loss\n        pbar.set_postfix({\"improvement\": improvement})\n\n        if np.isnan(improvement):\n            break\n        elif improvement &lt; stop_loss:\n            no_progress += 1\n        else:\n            no_progress = 0\n\n        if no_progress &gt; patience:\n            break\n\n    tdelta = time.time() - t0\n    gof_qualifiers = {\n        \"loss\": loss,\n        \"log_likelihood\": -loss,\n        \"n_iter\": i + 1,\n        \"elapsed\": tdelta,\n        \"iter/s\": (i + 1) / tdelta,\n    }\n\n    result = FitResult(\n        fit_parameters=parameters_current,\n        fixed_parameters=self.fixed_parameters.guess,\n        gof_qualifiers=gof_qualifiers,\n        guess=self.free_parameters.guess,\n        base_result=base_result,\n    )\n\n    return result\n</code></pre>"},{"location":"reference/minimizers/#minimizers.parse_scipy_options","title":"<code>parse_scipy_options(minimizer_options)</code>","text":"<p>rename options for scipy minimizer</p> Source code in <code>slimfit/minimizers.py</code> <pre><code>def parse_scipy_options(minimizer_options: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"rename options for scipy minimizer\"\"\"\n\n    kwargs = minimizer_options.copy()\n    options = minimizer_options.get(\"options\", {})\n    if \"max_iter\" in kwargs:\n        options[\"maxiter\"] = kwargs.pop(\"max_iter\")\n    if \"disp\" in kwargs:\n        options[\"disp\"] = kwargs.pop(\"disp\")\n    if options:\n        kwargs[\"options\"] = options\n\n    return kwargs\n</code></pre>"},{"location":"reference/models/","title":"models","text":""},{"location":"reference/models/#models.Model","title":"<code>Model</code>","text":"<p>               Bases: <code>CompositeExpr</code></p> Source code in <code>slimfit/models.py</code> <pre><code>class Model(slimfit.base.CompositeExpr):\n    def __init__(\n        self,\n        expr: dict[Symbol | str, Expr | slimfit.base.NumExprBase | MatrixBase],\n    ):\n        # currently typing has a small problem where keys are expected to be `str`, not symbol\n        super().__init__(expr)\n\n    def __repr__(self):\n        return f\"Model({self.expr.__repr__()})\"\n\n    @property\n    def dependent_symbols(self) -&gt; dict[str, Symbol]:\n        # todo needs to be updated\n        \"\"\"Variables corresponding to dependent (measured) data, given as keys in the model dict\"\"\"\n\n        return {symbol.name: symbol for symbol in self.expr.keys()}\n\n    @property\n    def components(self) -&gt; dict[str, slimfit.base.NumExprBase]:\n        \"\"\"all NumExprBase components in the model\n        keys should be such that their commectivity can be reconstructed ?\n        ie {Mul[0]MatMul[1]: &lt;component&gt; ...}\n        which tells us that this component is the second element of a matmul whose result\n        is the first component in a mul\n        \"\"\"\n        raise NotImplementedError(\"not yet implemented\")\n\n        # return {symbol.name: expr for symbol, expr in self.expr.items()}\n\n    def define_parameters(\n        self,\n        parameters: dict[str, npt.ArrayLike] | Iterable[str] | str = \"*\",\n    ) -&gt; Parameters:\n        \"\"\"\n        Defines and initializes parameters for the model.\n\n        This method accepts parameters in various forms (dictionary, iterable, or string)\n        and returns an instance of the Parameters class, initialized with the provided\n        parameters and the existing symbols of the model. Default value is '*', which\n        returns all the model's symbols as parameters.\n\n        Args:\n            parameters:\n            The parameters to define for the model. Can be a dictionary with parameter\n            names as keys and corresponding values, an iterable of parameter names, or a\n            single parameter name as a string.\n\n        Returns:\n            Parameters: An instance of the Parameters class, initialized with the provided\n            parameters and the existing symbols of the model.\n\n        Usage:\n            Assuming we have a model instance 'm' and we want to define the symbols 'a' and 'b'\n            are parameters:\n\n            ```python\n            defined_parameters = m.define_parameters(\"a b\")\n            ```\n\n            Use a dictionary to define parameters and provide initial guesses:\n            ```python\n            guess = {'a': 3., 'b': 10}\n            defined_parameters = m.define_parameters(guess)\n            ```\n\n        \"\"\"\n        # TODO allow specification of parameters as symbols\n\n        from slimfit.parameter import Parameters\n\n        parameters = Parameters.from_symbols(self.symbols, parameters)\n\n        return parameters\n</code></pre>"},{"location":"reference/models/#models.Model.components","title":"<code>components</code>  <code>property</code>","text":"<p>all NumExprBase components in the model keys should be such that their commectivity can be reconstructed ? ie {Mul[0]MatMul[1]:  ...} which tells us that this component is the second element of a matmul whose result is the first component in a mul"},{"location":"reference/models/#models.Model.dependent_symbols","title":"<code>dependent_symbols</code>  <code>property</code>","text":"<p>Variables corresponding to dependent (measured) data, given as keys in the model dict</p>"},{"location":"reference/models/#models.Model.define_parameters","title":"<code>define_parameters(parameters='*')</code>","text":"<p>Defines and initializes parameters for the model.</p> <p>This method accepts parameters in various forms (dictionary, iterable, or string) and returns an instance of the Parameters class, initialized with the provided parameters and the existing symbols of the model. Default value is '*', which returns all the model's symbols as parameters.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>dict[str, ArrayLike] | Iterable[str] | str</code> <code>'*'</code> <p>Returns:</p> Name Type Description <code>Parameters</code> <code>Parameters</code> <p>An instance of the Parameters class, initialized with the provided</p> <code>Parameters</code> <p>parameters and the existing symbols of the model.</p> Usage <p>Assuming we have a model instance 'm' and we want to define the symbols 'a' and 'b' are parameters:</p> <pre><code>defined_parameters = m.define_parameters(\"a b\")\n</code></pre> <p>Use a dictionary to define parameters and provide initial guesses: <pre><code>guess = {'a': 3., 'b': 10}\ndefined_parameters = m.define_parameters(guess)\n</code></pre></p> Source code in <code>slimfit/models.py</code> <pre><code>def define_parameters(\n    self,\n    parameters: dict[str, npt.ArrayLike] | Iterable[str] | str = \"*\",\n) -&gt; Parameters:\n    \"\"\"\n    Defines and initializes parameters for the model.\n\n    This method accepts parameters in various forms (dictionary, iterable, or string)\n    and returns an instance of the Parameters class, initialized with the provided\n    parameters and the existing symbols of the model. Default value is '*', which\n    returns all the model's symbols as parameters.\n\n    Args:\n        parameters:\n        The parameters to define for the model. Can be a dictionary with parameter\n        names as keys and corresponding values, an iterable of parameter names, or a\n        single parameter name as a string.\n\n    Returns:\n        Parameters: An instance of the Parameters class, initialized with the provided\n        parameters and the existing symbols of the model.\n\n    Usage:\n        Assuming we have a model instance 'm' and we want to define the symbols 'a' and 'b'\n        are parameters:\n\n        ```python\n        defined_parameters = m.define_parameters(\"a b\")\n        ```\n\n        Use a dictionary to define parameters and provide initial guesses:\n        ```python\n        guess = {'a': 3., 'b': 10}\n        defined_parameters = m.define_parameters(guess)\n        ```\n\n    \"\"\"\n    # TODO allow specification of parameters as symbols\n\n    from slimfit.parameter import Parameters\n\n    parameters = Parameters.from_symbols(self.symbols, parameters)\n\n    return parameters\n</code></pre>"},{"location":"reference/np_funcs/","title":"np_funcs","text":""},{"location":"reference/numerical/","title":"numerical","text":""},{"location":"reference/numerical/#numerical.DummyNumExpr","title":"<code>DummyNumExpr</code>","text":"<p>               Bases: <code>NumExprBase</code></p> <p>Dummy callable object which returns supplied 'obj' when called Has no parameters or symbols</p> Source code in <code>slimfit/numerical.py</code> <pre><code>class DummyNumExpr(NumExprBase):\n    \"\"\"Dummy callable object which returns supplied 'obj' when called\n    Has no parameters or symbols\n    \"\"\"\n\n    def __init__(self, obj: Any, *args, **kwargs):\n        #\n        super().__init__(*args, **kwargs)\n        self.obj = obj\n\n    def __call__(self, **kwargs):\n        return self.obj\n\n    @property\n    def symbols(self) -&gt; set[Symbol]:\n        return set()\n\n    @property\n    def shape(self) -&gt; Shape:\n        try:\n            return self.obj.shape\n        except AttributeError:\n            return ()\n</code></pre>"},{"location":"reference/numerical/#numerical.GMM","title":"<code>GMM</code>","text":"<p>               Bases: <code>CompositeExpr</code></p> Source code in <code>slimfit/numerical.py</code> <pre><code>class GMM(CompositeExpr):\n    # todo can also be implemented as normal NumExpr but with broadcasting parameter shapes\n    # important is that GMM class allows users to find oud positions of parmaeters in mu / sigma\n    # matrices for EM GMM optimization.\n\n    def __init__(\n        self,\n        x: Symbol | NumExpr,\n        mu: Matrix | MatrixNumExpr,\n        sigma: Matrix | MatrixNumExpr,\n        name: Optional[str] = None,\n    ):\n        # check for the correct shape when creating from sympy Matrix\n        if isinstance(mu, Matrix) and mu.shape[0] != 1:\n            raise ValueError(\n                \"GMM parameter matrices must be of shape (1, N) where N is the number of states.\"\n            )\n\n        expr = {\"x\": x, \"mu\": mu, \"sigma\": sigma}\n\n        # todo some kind of properties object for this metadata\n        name = name or \"GMM\"  # counter for number of instances?\n        self.kind = \"gmm\"\n        super().__init__(expr)\n\n    def __call__(self, **kwargs) -&gt; np.ndarray:\n        result = super().__call__(**kwargs)\n\n        x, mu, sig = result[\"x\"], result[\"mu\"], result[\"sigma\"]\n        output = 1 / (np.sqrt(2 * np.pi) * sig) * np.exp(-np.power((x - mu) / sig, 2) / 2)\n\n        # Output shape is (datapoints, states, 1) to match output shape of matrix\n        # exponentiation model\n        return np.expand_dims(output, -1)\n\n    def __repr__(self):\n        return f\"GMM({self.expr['x']}, {self.expr['mu']}, {self.expr['sigma']})\"\n\n    def to_numerical(self) -&gt; GMM:\n        # todo probably this is the same as the super class method\n        num_expr = {k: to_numerical(expr) for k, expr in self.items()}\n        instance = GMM(**num_expr)\n\n        return instance\n\n    @property\n    def shape(self) -&gt; Shape:\n        shape = super().shape\n        return shape + (1,)\n\n    @property\n    def states(self) -&gt; Optional[list[str]]:\n        \"\"\"\n        List of state names, if naming scheme of mu's is of format `mu_&lt;state_name&gt;`.\n        \"\"\"\n\n        mus, suffices = zip(*(elem.name.split(\"_\") for elem in self[\"mu\"]))\n\n        if all((mu == \"mu\" for mu in mus)):\n            return list(suffices)\n        else:\n            return None\n</code></pre>"},{"location":"reference/numerical/#numerical.GMM.states","title":"<code>states</code>  <code>property</code>","text":"<p>List of state names, if naming scheme of mu's is of format <code>mu_&lt;state_name&gt;</code>.</p>"},{"location":"reference/numerical/#numerical.MarkovIVP","title":"<code>MarkovIVP</code>","text":"<p>               Bases: <code>CompositeExpr</code></p> <p>Uses scipy.integrate.solve_ivp to numerically find time evolution of a markov process     given a transition rate matrix.</p> <p>Returned shape is (len(t_var), len(y0), 1), or (, , 1) Source code in <code>slimfit/numerical.py</code> <pre><code>class MarkovIVP(CompositeExpr):\n    \"\"\"Uses scipy.integrate.solve_ivp to numerically find time evolution of a markov process\n        given a transition rate matrix.\n\n    Returned shape is (len(t_var), len(y0), 1), or (&lt;datapoints&gt;, &lt;states&gt;, 1)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        t: Symbol | NumExpr,\n        trs_matrix: Matrix | MatrixNumExpr,\n        y0: Matrix | MatrixNumExpr,\n        domain: Optional[tuple[float, float]] = None,\n        **ivp_kwargs,\n    ):\n        expr = {\"t\": t, \"trs_matrix\": trs_matrix, \"y0\": y0}\n\n        super().__init__(expr)\n\n        ivp_defaults = {\"method\": \"Radau\"}\n        self.ivp_defaults = ivp_defaults | ivp_kwargs\n        self.domain = domain\n\n    def __call__(self, **kwargs):\n        result = super().__call__(**kwargs)\n\n        # if `self['t']` does not depend on any parameters; domain can be precomputed and\n        # does not have to be determined for every call\n        # although its every fast to do so\n        domain = self.domain or self.get_domain(result[\"t\"])\n        sol = solve_ivp(\n            self.grad_func,\n            domain,\n            y0=result[\"y0\"].squeeze(),\n            t_eval=result[\"t\"],\n            args=(result[\"trs_matrix\"],),\n            **self.ivp_defaults,\n        )\n\n        # shape is modified to match the output shape of matrix exponentiation model\n        # exp(m*t) @ y0, which is (datapoints, states, 1)\n        return np.expand_dims(sol.y.T, -1)\n\n    # TODO generalize\n    def to_numerical(self) -&gt; MarkovIVP:\n        num_expr = {k: to_numerical(expr) for k, expr in self.items()}\n        instance = MarkovIVP(**num_expr, domain=self.domain, **self.ivp_defaults)\n\n        return instance\n\n    def get_domain(self, arr: np.ndarray) -&gt; tuple[float, float]:\n        # padding?\n        return arr[0], arr[-1]\n\n    @staticmethod\n    def grad_func(t, y, trs_matrix):\n        return trs_matrix @ y\n</code></pre>"},{"location":"reference/numerical/#numerical.MatrixNumExpr","title":"<code>MatrixNumExpr</code>","text":"<p>               Bases: <code>NumExpr</code></p> Source code in <code>slimfit/numerical.py</code> <pre><code>class MatrixNumExpr(NumExpr):\n    def __init__(\n        self,\n        expr: MatrixBase,\n        name: Optional[str] = None,\n        kind: Optional[str] = None,\n    ):\n        if not isinstance(expr, MatrixBase):\n            raise TypeError(\"Expression must be an instance of MatrixParameter or sympy.Matrix\")\n        self._name = name\n\n        # Callable type is used by minimizers to determine solving strategy\n        if kind is None:\n            self.kind = identify_expression_kind(expr)\n        elif isinstance(kind, str):\n            self.kind: str = kind.lower()\n        else:\n            raise TypeError(\"Invalid type for 'kind', must be 'str'\")\n\n        super().__init__(expr)\n\n    @property\n    def name(self) -&gt; str:\n        if self._name:\n            return self._name\n        if self.kind == \"constant\":\n            symbol_names = [str(symbol) for symbol in self.expr]\n            prefix = [name.split(\"_\")[0] for name in symbol_names]\n            if len(set(prefix)) == 1:  # All prefixes are identical, prefix is the name\n                return prefix[0]\n        else:\n            return \"M\"\n\n    @name.setter\n    def name(self, name):\n        self._name = name\n\n    @property\n    def shape(self) -&gt; Shape:\n        # again there might be problems depending on how the matrix elements depend on\n        # different combinations of parameters and data\n        # for now we assume this is the same for all elements\n\n        # Find the shape from broadcasting parameters and data\n        base_shape = super().shape\n\n        # squeeze last dim if shape is (1,)\n        base_shape = () if base_shape == (1,) else base_shape\n        shape = base_shape + self.expr.shape\n\n        return shape\n\n    @cached_property\n    def element_mapping(self) -&gt; dict[Symbol, tuple[int, int]]:\n        \"\"\"\n        Dictionary mapping Symbol to matrix indices\n        only returns entries if the matrix element is equal to a `Symbol`, not `Expr`\n        \"\"\"\n\n        element_mapping = {}\n        for i, j in np.ndindex(self.expr.shape):\n            elem = self.expr[i, j]\n            if isinstance(elem, Symbol):\n                element_mapping[elem] = (i, j)\n        return element_mapping\n\n    @cached_property\n    def lambdified(self) -&gt; np.ndarray:\n        \"\"\"Array of lambdified function per matrix element\"\"\"\n        # TODO scalercallable per element\n\n        lambdas = np.empty(self.expr.shape, dtype=object)\n        # todo might go wrong when not all elements have the same parameters\n        for i, j in np.ndindex(self.expr.shape):\n            lambdas[i, j] = lambdify(sorted(self.symbols, key=str), self.expr[i, j])\n\n        return lambdas\n\n    def forward(self, **kwargs):\n        \"\"\"forward pass with type checking\n\n        or without?\n        \"\"\"\n        ...\n\n    def __call__(self, **kwargs: float) -&gt; np.ndarray:\n        # https://github.com/sympy/sympy/issues/5642\n        # Prepare kwargs for lambdified\n        # try:\n        #     parameters: dict[str, np.ndarray | float] = {\n        #         k: kwargs[k] for k in self.free_parameters.keys()\n        #     }\n        # except KeyError as e:\n        #     raise KeyError(f\"Missing value for parameter {e}\") from e\n\n        # check shapes\n        # this should move somewhere else\n        # for p_name, p_value in parameters.items():\n        #     if getattr(p_value, \"shape\", tuple()) != self.parameters[p_name].shape:\n        #         raise ValueError(f\"Shape mismatch for parameter {p_name}\")\n\n        ld_kwargs = self.parse_kwargs(**kwargs)\n\n        # todo precomputed shapes\n        # try:\n        #     # Shape is given be pre-specified shape\n        #     shape = self.shape\n        # except AttributeError:\n        base_shape = np.broadcast_shapes(\n            *(getattr(value, \"shape\", tuple()) for value in ld_kwargs.values())\n        )\n\n        # squeeze last dim if shape is (1,)\n        base_shape = () if base_shape == (1,) else base_shape\n        shape = base_shape + self.expr.shape\n\n        out = np.empty(shape)\n        for i, j in np.ndindex(self.expr.shape):\n            out[..., i, j] = self.lambdified[i, j](**ld_kwargs)\n\n        return out\n\n    @property\n    def values(self) -&gt; np.ndarray:\n        \"\"\"\n\n        Returns: Array with elements set to parameter values\n\n        \"\"\"\n        raise DeprecationWarning(\"Deprecate in favour of `value`\")\n        arr = np.empty(self.shape)\n        for i, j in np.ndindex(self.shape):\n            arr[i, j] = self.expr[i, j].value\n\n        return arr\n\n    def __getitem__(self, key):\n        return self.expr[key]\n\n    def __contains__(self, item) -&gt; bool:\n        return self.expr.__contains__(item)\n\n    # this is more of a str than a repr\n    def __repr__(self):\n        names = sorted(self.symbol_names)\n        name = self.name or \"MatrixNumExpr\"\n        return f\"{name}({', '.join(names)})\"\n\n    def index(self, symbol: Symbol) -&gt; tuple[int, int]:\n        \"\"\"\n        Returns indices of parameter for Matrix Expressions\n\n        Args:\n            name: Parameter name to find matrix elements of\n\n        Returns: Tuple of matrix elements ij\n\n        \"\"\"\n\n        return self.element_mapping[symbol]\n</code></pre>"},{"location":"reference/numerical/#numerical.MatrixNumExpr.element_mapping","title":"<code>element_mapping</code>  <code>cached</code> <code>property</code>","text":"<p>Dictionary mapping Symbol to matrix indices only returns entries if the matrix element is equal to a <code>Symbol</code>, not <code>Expr</code></p>"},{"location":"reference/numerical/#numerical.MatrixNumExpr.lambdified","title":"<code>lambdified</code>  <code>cached</code> <code>property</code>","text":"<p>Array of lambdified function per matrix element</p>"},{"location":"reference/numerical/#numerical.MatrixNumExpr.values","title":"<code>values</code>  <code>property</code>","text":"<p>Returns: Array with elements set to parameter values</p>"},{"location":"reference/numerical/#numerical.MatrixNumExpr.forward","title":"<code>forward(**kwargs)</code>","text":"<p>forward pass with type checking</p> <p>or without?</p> Source code in <code>slimfit/numerical.py</code> <pre><code>def forward(self, **kwargs):\n    \"\"\"forward pass with type checking\n\n    or without?\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/numerical/#numerical.MatrixNumExpr.index","title":"<code>index(symbol)</code>","text":"<p>Returns indices of parameter for Matrix Expressions</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Parameter name to find matrix elements of</p> required <p>Returns: Tuple of matrix elements ij</p> Source code in <code>slimfit/numerical.py</code> <pre><code>def index(self, symbol: Symbol) -&gt; tuple[int, int]:\n    \"\"\"\n    Returns indices of parameter for Matrix Expressions\n\n    Args:\n        name: Parameter name to find matrix elements of\n\n    Returns: Tuple of matrix elements ij\n\n    \"\"\"\n\n    return self.element_mapping[symbol]\n</code></pre>"},{"location":"reference/numerical/#numerical.NumberExpr","title":"<code>NumberExpr</code>","text":"<p>               Bases: <code>NumExprBase</code></p> <p>callable object for sympy <code>Number</code>s</p> Source code in <code>slimfit/numerical.py</code> <pre><code>class NumberExpr(NumExprBase):\n    \"\"\"callable object for sympy `Number`s\"\"\"\n\n    def __init__(self, obj: Any, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.obj = obj\n\n    def __call__(self, **kwargs):\n        return self.obj.evalf()\n\n    @property\n    def symbols(self) -&gt; set[Symbol]:\n        return set()\n\n    @property\n    def shape(self) -&gt; Shape:\n        try:\n            return self.obj.shape\n        except AttributeError:\n            return ()\n</code></pre>"},{"location":"reference/numerical/#numerical.identify_expression_kind","title":"<code>identify_expression_kind(sympy_expression)</code>","text":"<p>Find the type of expression</p> <p>Only implemented for 'constant' kind, otherwise return is generic</p> Source code in <code>slimfit/numerical.py</code> <pre><code>def identify_expression_kind(sympy_expression: Union[Expr, MatrixBase]) -&gt; str:\n    \"\"\"Find the type of expression\n\n    Only implemented for 'constant' kind, otherwise return is generic\n\n    \"\"\"\n\n    # check for gaussian mixture model ...\n\n    if isinstance(sympy_expression, MatrixBase):\n        ...\n\n        if all(isinstance(elem, Symbol) for elem in sympy_expression):\n            # this should also check the symbols for their shapes, for it to be constant\n            # the elements should all be scalars\n            return \"constant\"\n\n    return \"generic\"\n</code></pre>"},{"location":"reference/numerical/#numerical.to_numerical","title":"<code>to_numerical(expression)</code>","text":"<p>Converts sympy expression to slimfit numerical expression</p> <p>if the expressions already is an NumExpr; the object is modified in-place by setting the parameters</p> Source code in <code>slimfit/numerical.py</code> <pre><code>def to_numerical(\n    expression: Union[NumExprBase, Expr, MatrixBase | Model | CompositeExpr],\n) -&gt; NumExprBase | CompositeExpr:\n    \"\"\"Converts sympy expression to slimfit numerical expression\n\n    if the expressions already is an NumExpr; the object is modified in-place by setting\n    the parameters\n\n    \"\"\"\n\n    if hasattr(expression, \"to_numerical\"):\n        return expression.to_numerical()\n    # elif isinstance(expression, Model):\n    #     model_dict = {lhs: to_numerical(rhs) for lhs, rhs in expression.items()}\n    #     from slimfit.models import NumericalModel\n    #\n    #     return NumericalModel(model_dict, parameters, data)\n    if isinstance(expression, HadamardProduct):\n        from slimfit.operations import Mul\n\n        return Mul(*(to_numerical(arg) for arg in expression.args))\n    elif isinstance(expression, MatrixBase):\n        return MatrixNumExpr(expression)\n    elif isinstance(expression, Expr):\n        return NumExpr(expression)\n    elif isinstance(expression, (np.ndarray, float, int)):\n        return DummyNumExpr(expression)\n    elif isinstance(expression, NumExprBase):\n        return expression\n    else:\n        raise TypeError(f\"Invalid type {type(expression)!r}\")\n</code></pre>"},{"location":"reference/objective/","title":"objective","text":""},{"location":"reference/objective/#objective.Objective","title":"<code>Objective</code>","text":"<p>Base class for objective functions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>Numerical model to call.</p> required <code>loss</code> <code>Loss</code> <p>Loss function to use.</p> required <code>xdata</code> <code>dict[str, ndarray]</code> <p>Input x data.</p> required <code>ydata</code> <code>dict[str, ndarray]</code> <p>Output y data to calculate loss against.</p> required <code>negate</code> <code>Literal[1, -1]</code> <p>Set to <code>-1</code> to negate objective return value. Used when minimizers are used for maximization problems such as likelihood fitting.</p> <code>1</code> Source code in <code>slimfit/objective.py</code> <pre><code>class Objective:\n    \"\"\"\n    Base class for objective functions.\n\n    Args:\n        model: Numerical model to call.\n        loss: Loss function to use.\n        xdata: Input x data.\n        ydata: Output y data to calculate loss against.\n        negate: Set to `-1` to negate objective return value. Used when minimizers are used for\n            maximization problems such as likelihood fitting.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Model,\n        loss: Loss,\n        xdata: dict[str, np.ndarray],\n        ydata: dict[str, np.ndarray],\n        negate: Literal[1, -1] = 1,\n    ):\n        self.model = model\n        self.loss = loss\n        self.xdata = xdata\n        self.ydata = ydata\n        self.negate = negate\n</code></pre>"},{"location":"reference/objective/#objective.ScipyObjective","title":"<code>ScipyObjective</code>","text":"<p>               Bases: <code>Objective</code></p> <p>Objective function for use with scipy.optimize.minimize or ScipyMinimizer.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>Numerical model to call.</p> required <code>loss</code> <code>Loss</code> <p>Loss function to use.</p> required <code>xdata</code> <code>dict[str, ndarray]</code> <p>Input x data.</p> required <code>ydata</code> <code>dict[str, ndarray]</code> <p>Output y data to calculate loss against.</p> required <code>shapes</code> <code>dict[str, Shape]</code> <p>Shapes of the parameters.</p> required <code>negate</code> <code>Literal[1, -1]</code> <p>Whether to negate the objective function output (negate for maximization).</p> <code>1</code> Source code in <code>slimfit/objective.py</code> <pre><code>class ScipyObjective(Objective):\n    \"\"\"\n    Objective function for use with scipy.optimize.minimize or ScipyMinimizer.\n\n    Args:\n        model: Numerical model to call.\n        loss: Loss function to use.\n        xdata: Input x data.\n        ydata: Output y data to calculate loss against.\n        shapes: Shapes of the parameters.\n        negate: Whether to negate the objective function output (negate for maximization).\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Model,\n        loss: Loss,\n        xdata: dict[str, np.ndarray],\n        ydata: dict[str, np.ndarray],\n        shapes: dict[str, Shape],\n        negate: Literal[1, -1] = 1,\n    ):\n        super().__init__(model=model, loss=loss, xdata=xdata, ydata=ydata, negate=negate)\n        self.shapes = shapes\n\n    def __call__(self, x: np.ndarray) -&gt; float:\n        \"\"\"\n        Call the objective function.\n\n        Args:\n            x: Array of concatenated parameters.\n\n        Returns:\n            Objective value.\n\n        \"\"\"\n\n        parameters = unpack(x, self.shapes)\n\n        y_model = self.model(**parameters, **self.xdata)\n        loss_value = self.loss(self.ydata, y_model)\n\n        return self.negate * loss_value\n\n    @property\n    def hessian(self) -&gt; Hessian:\n        return Hessian(**self.__dict__)\n</code></pre>"},{"location":"reference/objective/#objective.ScipyObjective.__call__","title":"<code>__call__(x)</code>","text":"<p>Call the objective function.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Array of concatenated parameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Objective value.</p> Source code in <code>slimfit/objective.py</code> <pre><code>def __call__(self, x: np.ndarray) -&gt; float:\n    \"\"\"\n    Call the objective function.\n\n    Args:\n        x: Array of concatenated parameters.\n\n    Returns:\n        Objective value.\n\n    \"\"\"\n\n    parameters = unpack(x, self.shapes)\n\n    y_model = self.model(**parameters, **self.xdata)\n    loss_value = self.loss(self.ydata, y_model)\n\n    return self.negate * loss_value\n</code></pre>"},{"location":"reference/objective/#objective.pack","title":"<code>pack(parameter_values)</code>","text":"<p>Pack a dictionary of parameter_name together as array</p> Source code in <code>slimfit/objective.py</code> <pre><code>def pack(\n    parameter_values: Iterable[np.ndarray],\n) -&gt; np.ndarray:  # todo iterable numerical dtype input\n    \"\"\"Pack a dictionary of parameter_name together as array\"\"\"\n\n    return np.concatenate(tuple(param_value.ravel() for param_value in parameter_values))\n</code></pre>"},{"location":"reference/objective/#objective.unpack","title":"<code>unpack(x, shapes)</code>","text":"<p>Unpack a ndim 1 array of concatenated parameter values into a dictionary of parameter name: parameter_value where parameter values are cast back to their specified shapes.</p> Source code in <code>slimfit/objective.py</code> <pre><code>def unpack(x: np.ndarray, shapes: dict[str, tuple[int, ...]]) -&gt; dict[str, np.ndarray]:\n    \"\"\"Unpack a ndim 1 array of concatenated parameter values into a dictionary of\n    parameter name: parameter_value where parameter values are cast back to their\n    specified shapes.\n    \"\"\"\n    sizes = [int(np.prod(shape)) for shape in shapes.values()]\n\n    x_split = np.split(x, np.cumsum(sizes))\n    p_values = {name: arr.reshape(shape) for (name, shape), arr in zip(shapes.items(), x_split)}\n\n    return p_values\n</code></pre>"},{"location":"reference/operations/","title":"operations","text":"<p>Model operations Currently only multiplications for probablities</p>"},{"location":"reference/operations/#operations.MatMul","title":"<code>MatMul</code>","text":"<p>               Bases: <code>CompositeArgsExpr</code></p> <p>matmul composite callable</p> <p>arguments must have .shape attribute and shape must be compatible with matrix multiplication</p> Source code in <code>slimfit/operations.py</code> <pre><code>class MatMul(CompositeArgsExpr):\n\n    \"\"\"\n    matmul composite callable\n\n    arguments must have .shape attribute and shape must be compatible with matrix multiplication\n\n    \"\"\"\n\n    def __init__(self, *args):\n        if len(args) != 2:\n            raise ValueError(\"MatMul takes exactly two arguments\")\n        super().__init__(*args)\n\n    def __call__(self, **kwargs):\n        result = self._call(**kwargs)\n        return result[0] @ result[1]\n\n    @property\n    def shape(self) -&gt; Shape:\n        raise NotImplementedError()\n\n    def __repr__(self) -&gt; str:\n        args = \", \".join([arg.__repr__() for arg in self.values()])\n        return f\"MatMul({args})\"\n</code></pre>"},{"location":"reference/operations/#operations.Mul","title":"<code>Mul</code>","text":"<p>               Bases: <code>CompositeArgsExpr</code></p> <p>Mul elementwise lazily</p> Source code in <code>slimfit/operations.py</code> <pre><code>class Mul(CompositeArgsExpr):\n    # might be subject to renaming\n    \"\"\"Mul elementwise lazily\"\"\"\n\n    def __init__(self, *args):\n        super().__init__(*args)\n\n    def __call__(self, **kwargs) -&gt; npt.ArrayLike:\n        result = self._call(**kwargs)\n\n        return reduce(mul, result.values())\n\n    def __repr__(self) -&gt; str:\n        args = \", \".join([arg.__repr__() for arg in self.values()])\n        return f\"Mul({args})\"\n</code></pre>"},{"location":"reference/parameter/","title":"parameter","text":""},{"location":"reference/parameter/#parameter.Parameter","title":"<code>Parameter</code>  <code>dataclass</code>","text":"Source code in <code>slimfit/parameter.py</code> <pre><code>@dataclass(frozen=True)\nclass Parameter:\n    symbol: Expr  # allow `str` after which __init___ finds the symbol?\n    guess: float | int | np.ndarray = field(default=1.0)\n    lower_bound: float | int | np.ndarray | None = field(default=None)\n    upper_bound: float | int | np.ndarray | None = field(default=None)\n    fixed: bool = field(default=False)\n\n    def __post_init__(self):\n        # If the `guess` has a shape, it must be the same as the symbol shape,\n        # if it has any.\n        if not isinstance(self.guess, (float, int, np.ndarray)):\n            raise TypeError(f\"Guess must be a float, int, or ndarray, not {type(self.guess)}\")\n        guess_shape = getattr(self.guess, \"shape\", None)\n        symbol_shape = getattr(self.symbol, \"shape\", guess_shape)\n        if guess_shape != symbol_shape:\n            raise ValueError(f\"Guess shape for symbol {self.symbol} does not match symbol shape\")\n\n    @property\n    def param_type(self) -&gt; ParamType:\n        if \"boolean\" in self.symbol.assumptions0:\n            return ParamType.BOOLEAN\n        elif \"integer\" in self.symbol.assumptions0:\n            return ParamType.DISCRETE\n        else:\n            return ParamType.CONTINUOUS\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        \"\"\"\n        Shape of the Parameter. First tries to infer the shape from `Parameter.symbol`, otherwise\n        from `Parameter.guess`, and returns an empty tuple if neither is found.\n\n        \"\"\"\n        if shape := getattr(self.symbol, \"shape\", None):\n            return shape\n        elif shape := getattr(self.guess, \"shape\", None):\n            return shape\n\n        # when the parameter is a scalar, return an empty tuple, which is the same shape as\n        # returned by np.asarray(3.).shape\n        return tuple()\n\n    @property\n    def name(self) -&gt; str:\n        # Do symbols always have names?\n        return self.symbol.name\n</code></pre>"},{"location":"reference/parameter/#parameter.Parameter.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Shape of the Parameter. First tries to infer the shape from <code>Parameter.symbol</code>, otherwise from <code>Parameter.guess</code>, and returns an empty tuple if neither is found.</p>"},{"location":"reference/parameter/#parameter.Parameters","title":"<code>Parameters</code>","text":"<p>               Bases: <code>UserList</code></p> <p>Parameter list object</p> <p>or maybe it should be a dict? Could potentially help the <code>Objective</code> to/from flat array of guesses for argument of scipy.minimize</p> Source code in <code>slimfit/parameter.py</code> <pre><code>class Parameters(UserList):\n    \"\"\"Parameter list object\n\n    or maybe it should be a dict?\n    Could potentially help the `Objective` to/from flat array of guesses for argument of scipy.minimize\n    \"\"\"\n\n    def __init__(self, initlist=None):\n        initlist = initlist or []\n        if not all(isinstance(p, Parameter) for p in initlist):\n            raise ValueError(\"All items must be of type Parameter\")\n        symbols = {p.symbol for p in initlist}\n        if len(symbols) != len(initlist):\n            raise ValueError(\"All parameters must be unique\")\n        super().__init__(initlist)\n\n    @classmethod\n    def from_symbols(\n        cls,\n        symbols: Iterable[Symbol],\n        parameters: dict[str, npt.ArrayLike] | Iterable[str] | str = \"*\",\n    ) -&gt; Parameters:\n        symbol_dict = {symbol.name: symbol for symbol in sorted(symbols, key=str)}\n\n        if parameters == \"*\":\n            p_list = [Parameter(symbol) for symbol in symbol_dict.values()]\n        elif isinstance(parameters, str):\n            p_list = [Parameter(symbol_dict[k]) for k in re.split(\"; |, |\\*|\\s+\", parameters)]\n\n        elif isinstance(parameters, dict):\n            p_list = []\n            for k, v in parameters.items():\n                if isinstance(v, (float, int)):\n                    p_list.append(Parameter(symbol_dict[k], guess=v))\n                else:\n                    p_list.append(Parameter(symbol_dict[k], guess=np.array(v)))\n        elif isinstance(parameters, Iterable):\n            p_list = [Parameter(symbol_dict[k]) for k in parameters]\n        else:\n            raise ValueError(\"Invalid value for 'parameters'\")\n        return cls(p_list)\n\n    @property\n    def _symbols(self) -&gt; list[Symbol]:\n        return [p.symbol for p in self]\n\n    @property\n    def _names(self) -&gt; list[str]:\n        return [p.name for p in self]\n\n    def index(self, item: Parameter | Symbol | str, *args) -&gt; int:\n        # are you really sure it shoulnt be a dict?\n        # perhaps not since they 'keys' could be str or symbols ?\n        if isinstance(item, Parameter):\n            return super().index(item, *args)\n        elif isinstance(item, Symbol):\n            return self._symbols.index(item, *args)\n        else:\n            return self._names.index(item, *args)\n\n    def get(self, symbol_or_name: Symbol | str) -&gt; Optional[Parameter]:\n        \"\"\"Returns the parameter with the given symbol or name, or None if not found.\"\"\"\n\n        try:\n            return self[self.index(symbol_or_name)]\n        except KeyError:\n            return None\n\n    def set(self, symbol_or_name: Symbol | str, **kwargs) -&gt; Parameters:\n        \"\"\"\n        Set attributes of a parameter in-place.\n\n        Args:\n            symbol_or_name: Symbol or name of the parameter to set.\n            **kwargs: Additional keyword arguments to set on the parameter.\n\n        Returns:\n            The `Parameters object (self).\n        \"\"\"\n        idx = self.index(symbol_or_name)\n\n        # todo sanitize kwargs\n        # todo replace\n        self[idx] = Parameter(**(asdict(self[idx]) | kwargs))\n\n        return self\n\n    def replace(self, symbol_or_name: Symbol | str, **kwargs) -&gt; Parameters:\n        \"\"\"\n        Replace a parameter fields and create a new `Parameters` object .\n\n        Args:\n            symbol_or_name: Symbol or name of the parameter to replace.\n            **kwargs: Additional keyword arguments to set on the parameter.\n\n        Returns:\n            New parameters object with replaced Parameter object.\n        \"\"\"\n        idx = self.index(symbol_or_name)\n\n        new_parameters = Parameters(self)\n        new_parameters[idx] = replace(self[idx], **kwargs)\n\n        return new_parameters\n\n    def update_guess(self, guess: dict[str | Symbol, np.ndarray | float]) -&gt; Parameters:\n        \"\"\"returns a new parameters object where guesses are updated\"\"\"\n\n        p_out = Parameters(self)\n        for identifier, value in guess.items():\n            idx = p_out.index(identifier)\n            p_out[idx] = Parameter(**(asdict(self[idx]) | dict(guess=value)))\n\n        return p_out\n\n    @property\n    def guess(self) -&gt; dict[str, np.ndarray]:\n        return {p.name: np.asarray(p.guess) for p in self}\n\n    @property\n    def shapes(self) -&gt; dict[str, tuple[int, ...]]:\n        return {p.name: p.shape for p in self}\n\n    @property\n    def symbols(self) -&gt; set[Symbol]:\n        return set(p.symbol for p in self)\n\n    @property\n    def free(self) -&gt; Parameters:\n        \"\"\"Returns a new `Parameters` object with only the free parameters.\"\"\"\n        return Parameters([p for p in self if not p.fixed])\n\n    @property\n    def fixed(self) -&gt; Parameters:\n        \"\"\"Returns a new `Parameters` object with only the fixed parameters.\"\"\"\n        return Parameters([p for p in self if p.fixed])\n\n    @property\n    def has_bounds(self) -&gt; bool:\n        \"\"\"Return `True` if any of the parameters has bounds.\"\"\"\n\n        for p in self:\n            if p.lower_bound is not None:\n                return True\n            if p.upper_bound is not None:\n                return True\n\n        return False\n</code></pre>"},{"location":"reference/parameter/#parameter.Parameters.fixed","title":"<code>fixed</code>  <code>property</code>","text":"<p>Returns a new <code>Parameters</code> object with only the fixed parameters.</p>"},{"location":"reference/parameter/#parameter.Parameters.free","title":"<code>free</code>  <code>property</code>","text":"<p>Returns a new <code>Parameters</code> object with only the free parameters.</p>"},{"location":"reference/parameter/#parameter.Parameters.has_bounds","title":"<code>has_bounds</code>  <code>property</code>","text":"<p>Return <code>True</code> if any of the parameters has bounds.</p>"},{"location":"reference/parameter/#parameter.Parameters.get","title":"<code>get(symbol_or_name)</code>","text":"<p>Returns the parameter with the given symbol or name, or None if not found.</p> Source code in <code>slimfit/parameter.py</code> <pre><code>def get(self, symbol_or_name: Symbol | str) -&gt; Optional[Parameter]:\n    \"\"\"Returns the parameter with the given symbol or name, or None if not found.\"\"\"\n\n    try:\n        return self[self.index(symbol_or_name)]\n    except KeyError:\n        return None\n</code></pre>"},{"location":"reference/parameter/#parameter.Parameters.replace","title":"<code>replace(symbol_or_name, **kwargs)</code>","text":"<p>Replace a parameter fields and create a new <code>Parameters</code> object .</p> <p>Parameters:</p> Name Type Description Default <code>symbol_or_name</code> <code>Symbol | str</code> <p>Symbol or name of the parameter to replace.</p> required <code>**kwargs</code> <p>Additional keyword arguments to set on the parameter.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Parameters</code> <p>New parameters object with replaced Parameter object.</p> Source code in <code>slimfit/parameter.py</code> <pre><code>def replace(self, symbol_or_name: Symbol | str, **kwargs) -&gt; Parameters:\n    \"\"\"\n    Replace a parameter fields and create a new `Parameters` object .\n\n    Args:\n        symbol_or_name: Symbol or name of the parameter to replace.\n        **kwargs: Additional keyword arguments to set on the parameter.\n\n    Returns:\n        New parameters object with replaced Parameter object.\n    \"\"\"\n    idx = self.index(symbol_or_name)\n\n    new_parameters = Parameters(self)\n    new_parameters[idx] = replace(self[idx], **kwargs)\n\n    return new_parameters\n</code></pre>"},{"location":"reference/parameter/#parameter.Parameters.set","title":"<code>set(symbol_or_name, **kwargs)</code>","text":"<p>Set attributes of a parameter in-place.</p> <p>Parameters:</p> Name Type Description Default <code>symbol_or_name</code> <code>Symbol | str</code> <p>Symbol or name of the parameter to set.</p> required <code>**kwargs</code> <p>Additional keyword arguments to set on the parameter.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Parameters</code> <p>The `Parameters object (self).</p> Source code in <code>slimfit/parameter.py</code> <pre><code>def set(self, symbol_or_name: Symbol | str, **kwargs) -&gt; Parameters:\n    \"\"\"\n    Set attributes of a parameter in-place.\n\n    Args:\n        symbol_or_name: Symbol or name of the parameter to set.\n        **kwargs: Additional keyword arguments to set on the parameter.\n\n    Returns:\n        The `Parameters object (self).\n    \"\"\"\n    idx = self.index(symbol_or_name)\n\n    # todo sanitize kwargs\n    # todo replace\n    self[idx] = Parameter(**(asdict(self[idx]) | kwargs))\n\n    return self\n</code></pre>"},{"location":"reference/parameter/#parameter.Parameters.update_guess","title":"<code>update_guess(guess)</code>","text":"<p>returns a new parameters object where guesses are updated</p> Source code in <code>slimfit/parameter.py</code> <pre><code>def update_guess(self, guess: dict[str | Symbol, np.ndarray | float]) -&gt; Parameters:\n    \"\"\"returns a new parameters object where guesses are updated\"\"\"\n\n    p_out = Parameters(self)\n    for identifier, value in guess.items():\n        idx = p_out.index(identifier)\n        p_out[idx] = Parameter(**(asdict(self[idx]) | dict(guess=value)))\n\n    return p_out\n</code></pre>"},{"location":"reference/reduce/","title":"reduce","text":""},{"location":"reference/symbols/","title":"symbols","text":""},{"location":"reference/symbols/#symbols.get_symbols","title":"<code>get_symbols(*symbolic_objects)</code>","text":"<p>Returns a dictionary of symbols if no object is given, only returns FitSymbols otherwise returns dict of symbols in the object</p> Source code in <code>slimfit/symbols.py</code> <pre><code>def get_symbols(*symbolic_objects) -&gt; dict[str, Symbol]:\n    \"\"\"Returns a dictionary of symbols\n    if no object is given, only returns FitSymbols\n    otherwise returns dict of symbols in the object\n    \"\"\"\n    if len(symbolic_objects) == 0:\n        return FitSymbol._instances\n    else:\n        symbols = set()\n        for symbolic_object in symbolic_objects:\n            if isinstance(symbolic_object, dict):\n                symbols = set()\n                for entry in itertools.chain(symbolic_object.keys(), symbolic_object.values()):\n                    try:\n                        # entry is a sympy `Expr` and has `free_symbols` as a set\n                        symbols |= entry.free_symbols\n                    except TypeError:\n                        # rhs is a slimfit `NumExpr` and has a `free_symbols` dictionary\n                        symbols |= set(entry.free_symbols.values())\n                return\n            elif isinstance(symbolic_object, (Expr, MatrixBase)):\n                symbols |= symbolic_object.free_symbols\n                # return {symbol.name: symbol for symbol in sorted(symbolic_object.free_symbols, key=str)}\n            else:\n                raise TypeError(f\"Invalid type {type(symbolic_object)!r}\")\n\n        return {symbol.name: symbol for symbol in sorted(symbols, key=str)}\n</code></pre>"},{"location":"reference/typing/","title":"typing","text":""},{"location":"reference/utils/","title":"utils","text":""},{"location":"reference/utils/#utils.clean_types","title":"<code>clean_types(d)</code>","text":"<p>cleans up nested dict/list/tuple/other <code>d</code> for exporting as yaml</p> <p>Converts library specific types to python native types, including numpy dtypes, OrderedDict, numpy arrays</p>"},{"location":"reference/utils/#utils.clean_types--httpsstackoverflowcomquestions59605943python-convert-types-in-deeply-nested-dictionary-or-array","title":"https://stackoverflow.com/questions/59605943/python-convert-types-in-deeply-nested-dictionary-or-array","text":"Source code in <code>slimfit/utils.py</code> <pre><code>def clean_types(d: Any) -&gt; Any:\n    \"\"\"cleans up nested dict/list/tuple/other `d` for exporting as yaml\n\n    Converts library specific types to python native types, including numpy dtypes,\n    OrderedDict, numpy arrays\n\n    # https://stackoverflow.com/questions/59605943/python-convert-types-in-deeply-nested-dictionary-or-array\n\n    \"\"\"\n    if isinstance(d, np.floating):\n        return float(d)\n\n    if isinstance(d, np.integer):\n        return int(d)\n\n    if isinstance(d, np.ndarray):\n        return d.tolist()\n\n    if isinstance(d, list):\n        return [clean_types(item) for item in d]\n\n    if isinstance(d, tuple):\n        return tuple(clean_types(item) for item in d)\n\n    if isinstance(d, OrderedDict):\n        return clean_types(dict(d))\n\n    if isinstance(d, dict):\n        return {k: clean_types(v) for k, v in d.items()}\n\n    else:\n        return d\n</code></pre>"},{"location":"reference/utils/#utils.format_indexer","title":"<code>format_indexer(indexer)</code>","text":"<p>Format a tuple of slice objects into a string that can be used to index a numpy array.</p> <p>More or less the inverse of <code>numpy.index_exp</code>.</p> <p>Parameters:</p> Name Type Description Default <code>indexer</code> <code>tuple[slice, int, None, Ellipsis]</code> <p>Tuple of indexing objects.</p> required Source code in <code>slimfit/utils.py</code> <pre><code>def format_indexer(indexer: tuple[slice, int, None, Ellipsis]) -&gt; str:\n    \"\"\"Format a tuple of slice objects into a string that can be used to index a numpy array.\n\n    More or less the inverse of `numpy.index_exp`.\n\n\n    Args:\n        indexer: Tuple of indexing objects.\n\n    \"\"\"\n\n    return f\"[{', '.join(_format_indexer(sl) for sl in indexer)}]\"\n</code></pre>"},{"location":"reference/utils/#utils.get_bounds","title":"<code>get_bounds(parameters)</code>","text":"<p>Get bounds for minimization. Args:     parameters: Iterable of Parameter objects.</p> <p>Returns:</p> Type Description <code>Optional[list[tuple[Optional[float], Optional[float]]]]</code> <p>Either a list of tuples to pass to <code>scipy.minimize</code> or None, if there are no bounds.</p> Source code in <code>slimfit/utils.py</code> <pre><code>def get_bounds(\n    parameters: Iterable[Parameter],\n) -&gt; Optional[list[tuple[Optional[float], Optional[float]]]]:\n    \"\"\"\n    Get bounds for minimization.\n    Args:\n        parameters: Iterable of Parameter objects.\n\n    Returns:\n        Either a list of tuples to pass to `scipy.minimize` or None, if there are no bounds.\n    \"\"\"\n    bounds = [(p.vmin, p.vmax) for p in parameters]\n\n    if all([(None, None) == b for b in bounds]):\n        return None\n    else:\n        return bounds\n</code></pre>"},{"location":"reference/utils/#utils.intersecting_component_symbols","title":"<code>intersecting_component_symbols(model_components, symbols)</code>","text":"<p>Finds and groups model components which have intersecting symbols.</p> <p>Parameters:</p> Name Type Description Default <code>model_components</code> <code>list[tuple[Symbol, NumExprBase]]</code> <p>Model components.</p> required <code>symbols</code> <code>set[Symbol]</code> <p>Set of symbols to consider for intersections.</p> required <p>Returns:</p> Type Description <code>list[Model]</code> <p>Reconstructed models (assuming orignal model was a product of models).</p> Source code in <code>slimfit/utils.py</code> <pre><code>def intersecting_component_symbols(\n    model_components: list[tuple[Symbol, NumExprBase]],\n    symbols: set[Symbol],\n) -&gt; list[Model]:\n    \"\"\"\n    Finds and groups model components which have intersecting symbols.\n\n    Args:\n        model_components: Model components.\n        symbols: Set of symbols to consider for intersections.\n\n    Returns:\n        Reconstructed models (assuming orignal model was a product of models).\n    \"\"\"\n\n    seen_models = []\n    seen_sets = []\n    for lhs, num_expr in model_components:\n        param_set = num_expr.symbols &amp; symbols\n        # param_set = set(num_expr.free_parameters.keys())\n\n        found = False\n        # look for sets of parameters we've seen so far, if found, append to the list of sets\n        for i, test_set in enumerate(seen_sets):\n            if param_set &amp; test_set:\n                # add additional items to this set of parameters\n                test_set |= param_set\n                seen_models[i].append((lhs, num_expr))\n                found = True\n        if not found:\n            seen_sets.append(param_set)\n            seen_models.append([(lhs, num_expr)])\n\n    # Next, piece together the dependent model parts as Model objects, restoring original multiplications\n    sub_models = []\n    for components in seen_models:\n        model_dict = defaultdict(list)\n        for lhs, rhs in components:\n            model_dict[lhs].append(rhs)\n\n        model_dict = {\n            lhs: rhs[0] if len(rhs) == 1 else Mul(*rhs) for lhs, rhs in model_dict.items()\n        }\n        sub_models.append(Model(model_dict))\n\n    return sub_models\n</code></pre>"},{"location":"reference/v2/composite_expr/","title":"composite_expr","text":""},{"location":"reference/v2/composite_expr/#v2.composite_expr.MarkovIVP","title":"<code>MarkovIVP</code>","text":"<p>               Bases: <code>CompositeExpr</code></p> <p>Uses scipy.integrate.solve_ivp to numerically find time evolution of a markov process     given a transition rate matrix.</p> <p>Returned shape is ,  Source code in <code>slimfit/v2/composite_expr.py</code> <pre><code>class MarkovIVP(CompositeExpr):\n    \"\"\"Uses scipy.integrate.solve_ivp to numerically find time evolution of a markov process\n        given a transition rate matrix.\n\n    Returned shape is &lt;states&gt;, &lt;datapoints&gt;\n\n    \"\"\"\n\n    def __init__(\n        self,\n        t: sp.Symbol | sp.Expr | Expr,\n        trs_matrix: sp.Matrix | Expr,\n        y0: sp.Matrix | Expr,\n        domain: Optional[tuple[float, float]] = None,\n        **ivp_kwargs,\n    ):\n        expr = as_expr({\"t\": t, \"trs_matrix\": trs_matrix, \"y0\": y0})\n        super().__init__(expr)\n\n        ivp_defaults = {\"method\": \"Radau\"}\n        self.ivp_defaults = ivp_defaults | ivp_kwargs\n        self.domain = domain\n\n    def __call__(self, **kwargs):\n        components = super().__call__(**kwargs)\n\n        # if `self['t']` does not depend on any parameters; domain can be precomputed and\n        # does not have to be determined for every call\n        # although its every fast to do so\n        domain = self.domain or self.get_domain(components[\"t\"])\n        sol = solve_ivp(\n            self.grad_func,\n            domain,\n            y0=components[\"y0\"].squeeze(),\n            t_eval=components[\"t\"],\n            args=(components[\"trs_matrix\"],),\n            **self.ivp_defaults,\n        )\n\n        return sol.y\n\n    def get_domain(self, arr: np.ndarray) -&gt; tuple[float, float]:\n        # padding?\n        return arr[0], arr[-1]\n\n    @staticmethod\n    def grad_func(t, y, trs_matrix):\n        return trs_matrix @ y\n</code></pre>"},{"location":"reference/v2/expr/","title":"expr","text":""},{"location":"reference/v2/expr/#v2.expr.Expr","title":"<code>Expr</code>","text":"Source code in <code>slimfit/v2/expr.py</code> <pre><code>class Expr:\n    def __init__(self, expr) -&gt; None:\n        self._expr = expr\n\n    @property\n    def expr(self):\n        return self._expr\n\n    @cached_property\n    def symbols(self) -&gt; set[sp.Symbol]:\n        return set()\n\n    def filter_kwargs(self, **kwargs) -&gt; dict[str, Numerical]:\n        \"\"\"Parse kwargs and take only the ones in `free_parameters`\"\"\"\n        try:\n            kwargs = {k: kwargs[k] for k in {s.name for s in self.symbols}}\n        except KeyError as e:\n            raise KeyError(f\"Missing value for {e}\") from e\n\n        return kwargs\n\n    def __getitem__(self, item):\n        return GetItem(self, item)\n\n    def __call__(self, **kwargs):\n        return self._expr\n</code></pre>"},{"location":"reference/v2/expr/#v2.expr.Expr.filter_kwargs","title":"<code>filter_kwargs(**kwargs)</code>","text":"<p>Parse kwargs and take only the ones in <code>free_parameters</code></p> Source code in <code>slimfit/v2/expr.py</code> <pre><code>def filter_kwargs(self, **kwargs) -&gt; dict[str, Numerical]:\n    \"\"\"Parse kwargs and take only the ones in `free_parameters`\"\"\"\n    try:\n        kwargs = {k: kwargs[k] for k in {s.name for s in self.symbols}}\n    except KeyError as e:\n        raise KeyError(f\"Missing value for {e}\") from e\n\n    return kwargs\n</code></pre>"},{"location":"reference/v2/loss/","title":"loss","text":""},{"location":"reference/v2/loss/#v2.loss.SELoss","title":"<code>SELoss</code>","text":"<p>sum/average reduction</p> Source code in <code>slimfit/v2/loss.py</code> <pre><code>class SELoss:\n    \"\"\"sum/average reduction\"\"\"\n</code></pre>"},{"location":"reference/v2/minimize/","title":"minimize","text":""},{"location":"reference/v2/model/","title":"model","text":""},{"location":"reference/v2/parameter/","title":"parameter","text":""},{"location":"reference/v2/parameter/#v2.parameter.Parameter","title":"<code>Parameter</code>  <code>dataclass</code>","text":"<p>A mutable parameter class that supports method chaining</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>@dataclass\nclass Parameter:\n    \"\"\"A mutable parameter class that supports method chaining\"\"\"\n\n    symbol: sp.Symbol\n    guess: Numerical = 1.0\n    bounds: tuple[Optional[Numerical], Optional[Numerical]] = (None, None)\n    fixed: bool = False\n\n    @property\n    def name(self) -&gt; str:\n        return self.symbol.name\n\n    @property\n    def shape(self) -&gt; tuple[int, ...]:\n        shape = getattr(self.guess, \"shape\", tuple())\n        return shape\n\n    def fix(self) -&gt; Parameter:\n        \"\"\"Fix the parameter at its current guess value\"\"\"\n        self.fixed = True\n        return self\n\n    def unfix(self) -&gt; Parameter:\n        \"\"\"Make the parameter free to vary\"\"\"\n        self.fixed = False\n        return self\n\n    def set_bounds(\n        self, lower: Optional[Numerical] = None, upper: Optional[Numerical] = None\n    ) -&gt; Parameter:\n        \"\"\"Set parameter bounds\"\"\"\n        self.bounds = (lower, upper)\n        return self\n\n    def set_guess(self, value: Numerical) -&gt; Parameter:\n        \"\"\"Set initial guess value\"\"\"\n        self.guess = value\n        return self\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameter.fix","title":"<code>fix()</code>","text":"<p>Fix the parameter at its current guess value</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def fix(self) -&gt; Parameter:\n    \"\"\"Fix the parameter at its current guess value\"\"\"\n    self.fixed = True\n    return self\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameter.set_bounds","title":"<code>set_bounds(lower=None, upper=None)</code>","text":"<p>Set parameter bounds</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def set_bounds(\n    self, lower: Optional[Numerical] = None, upper: Optional[Numerical] = None\n) -&gt; Parameter:\n    \"\"\"Set parameter bounds\"\"\"\n    self.bounds = (lower, upper)\n    return self\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameter.set_guess","title":"<code>set_guess(value)</code>","text":"<p>Set initial guess value</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def set_guess(self, value: Numerical) -&gt; Parameter:\n    \"\"\"Set initial guess value\"\"\"\n    self.guess = value\n    return self\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameter.unfix","title":"<code>unfix()</code>","text":"<p>Make the parameter free to vary</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def unfix(self) -&gt; Parameter:\n    \"\"\"Make the parameter free to vary\"\"\"\n    self.fixed = False\n    return self\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters","title":"<code>Parameters</code>","text":"<p>Container for managing multiple parameters</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>class Parameters:\n    \"\"\"Container for managing multiple parameters\"\"\"\n\n    def __init__(self, parameters: Iterable[Parameter]):\n        self._parameters = {p.name: p for p in parameters}\n\n    def __getitem__(self, key: Union[str, Sequence[str]]) -&gt; Union[Parameter, Parameters]:\n        \"\"\"Get a parameter or create a new ParameterSet with selected parameters\"\"\"\n        if isinstance(key, str):\n            return self._parameters[key]\n        return Parameters([self._parameters[k] for k in key])\n\n    def __iter__(self):\n        return iter(self._parameters.values())\n\n    def __len__(self):\n        return len(self._parameters)\n\n    def __add__(self, other: Parameters) -&gt; Parameters:\n        return Parameters(self.to_list() + other.to_list())\n\n    @classmethod\n    def from_symbols(\n        cls,\n        symbols: Iterable[sp.Symbol],\n    ) -&gt; Parameters:\n        symbol_dict = {symbol.name: symbol for symbol in sorted(symbols, key=str)}\n\n        p_list = [Parameter(symbol) for symbol in symbol_dict.values()]\n        return cls(p_list)\n\n    @property\n    def guess(self) -&gt; dict[str, Numerical]:  # other types?\n        return {p.name: np.asarray(p.guess) for p in self}\n\n    def fix(self, *names: str) -&gt; Parameters:\n        \"\"\"Fix specified parameters\"\"\"\n        for name in names:\n            self._parameters[name].fix()\n        return self\n\n    def unfix(self, *names: str) -&gt; Parameters:\n        \"\"\"Unfix specified parameters\"\"\"\n        for name in names:\n            self._parameters[name].unfix()\n        return self\n\n    def set_bounds(\n        self, bounds_dict: dict[str, tuple[Optional[Numerical], Optional[Numerical]]]\n    ) -&gt; Parameters:\n        \"\"\"Set bounds for multiple parameters at once\"\"\"\n        for name, (lower, upper) in bounds_dict.items():\n            self._parameters[name].set_bounds(lower, upper)\n        return self\n\n    def set_guesses(self, guess_dict: dict[str, Numerical]) -&gt; Parameters:\n        \"\"\"Set initial guesses for multiple parameters at once\"\"\"\n        for name, guess in guess_dict.items():\n            self._parameters[name].set_guess(guess)\n        return self\n\n    @property\n    def fixed(self) -&gt; Parameters:\n        \"\"\"Get list of fixed parameters\"\"\"\n        return Parameters([p for p in self._parameters.values() if p.fixed])\n\n    @property\n    def free(self) -&gt; Parameters:\n        \"\"\"Get list of free parameters\"\"\"\n        return Parameters([p for p in self._parameters.values() if not p.fixed])\n\n    def to_list(self) -&gt; list[Parameter]:\n        \"\"\"Convert to parameter list\"\"\"\n        return list(self._parameters.values())\n\n    def __repr__(self) -&gt; str:\n        return f\"Parameters({list(self._parameters.values())})\"\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters.fixed","title":"<code>fixed</code>  <code>property</code>","text":"<p>Get list of fixed parameters</p>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters.free","title":"<code>free</code>  <code>property</code>","text":"<p>Get list of free parameters</p>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get a parameter or create a new ParameterSet with selected parameters</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def __getitem__(self, key: Union[str, Sequence[str]]) -&gt; Union[Parameter, Parameters]:\n    \"\"\"Get a parameter or create a new ParameterSet with selected parameters\"\"\"\n    if isinstance(key, str):\n        return self._parameters[key]\n    return Parameters([self._parameters[k] for k in key])\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters.fix","title":"<code>fix(*names)</code>","text":"<p>Fix specified parameters</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def fix(self, *names: str) -&gt; Parameters:\n    \"\"\"Fix specified parameters\"\"\"\n    for name in names:\n        self._parameters[name].fix()\n    return self\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters.set_bounds","title":"<code>set_bounds(bounds_dict)</code>","text":"<p>Set bounds for multiple parameters at once</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def set_bounds(\n    self, bounds_dict: dict[str, tuple[Optional[Numerical], Optional[Numerical]]]\n) -&gt; Parameters:\n    \"\"\"Set bounds for multiple parameters at once\"\"\"\n    for name, (lower, upper) in bounds_dict.items():\n        self._parameters[name].set_bounds(lower, upper)\n    return self\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters.set_guesses","title":"<code>set_guesses(guess_dict)</code>","text":"<p>Set initial guesses for multiple parameters at once</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def set_guesses(self, guess_dict: dict[str, Numerical]) -&gt; Parameters:\n    \"\"\"Set initial guesses for multiple parameters at once\"\"\"\n    for name, guess in guess_dict.items():\n        self._parameters[name].set_guess(guess)\n    return self\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters.to_list","title":"<code>to_list()</code>","text":"<p>Convert to parameter list</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def to_list(self) -&gt; list[Parameter]:\n    \"\"\"Convert to parameter list\"\"\"\n    return list(self._parameters.values())\n</code></pre>"},{"location":"reference/v2/parameter/#v2.parameter.Parameters.unfix","title":"<code>unfix(*names)</code>","text":"<p>Unfix specified parameters</p> Source code in <code>slimfit/v2/parameter.py</code> <pre><code>def unfix(self, *names: str) -&gt; Parameters:\n    \"\"\"Unfix specified parameters\"\"\"\n    for name in names:\n        self._parameters[name].unfix()\n    return self\n</code></pre>"},{"location":"reference/v2/symbol/","title":"symbol","text":""},{"location":"reference/v2/typing/","title":"typing","text":""},{"location":"tutorial/basic_usage/","title":"Basic Usage","text":"<p>Fitting in <code>slimfit</code> starts with model definition using standard sympy syntax.</p> In\u00a0[1]: Copied! <pre>from sympy import Symbol\nfrom slimfit.models import Model\n\nmodel = Model({Symbol(\"y\"): Symbol(\"a\") * Symbol(\"x\") + Symbol(\"b\")})\n</pre> from sympy import Symbol from slimfit.models import Model  model = Model({Symbol(\"y\"): Symbol(\"a\") * Symbol(\"x\") + Symbol(\"b\")}) <p>Generate some ground-truth data to fit to the model:</p> In\u00a0[2]: Copied! <pre>import numpy as np\n\ngt = {\"a\": 0.5, \"b\": 2.5}\nxdata = np.linspace(0, 11, num=100)\nydata = gt[\"a\"] * xdata + gt[\"b\"]\n\nnp.random.seed(43)\nnoise = np.random.normal(0, scale=ydata / 10.0 + 0.2)\nydata += noise\n\nDATA = {\"x\": xdata, \"y\": ydata}\n</pre> import numpy as np  gt = {\"a\": 0.5, \"b\": 2.5} xdata = np.linspace(0, 11, num=100) ydata = gt[\"a\"] * xdata + gt[\"b\"]  np.random.seed(43) noise = np.random.normal(0, scale=ydata / 10.0 + 0.2) ydata += noise  DATA = {\"x\": xdata, \"y\": ydata} <p>The model's parameters are a subset of the model's symbols, and are defined using a <code>Parameters</code> object. <code>Model</code> objects have a shorthand constructor method to directly create parameters from a model.</p> In\u00a0[3]: Copied! <pre>from slimfit.parameter import Parameters\n\nparameters = model.define_parameters(\"a b\")\nparameters\n</pre> from slimfit.parameter import Parameters  parameters = model.define_parameters(\"a b\") parameters Out[3]: <pre>Parameters([Parameter(symbol=a, guess=1.0, lower_bound=None, upper_bound=None, fixed=False),\n            Parameter(symbol=b, guess=1.0, lower_bound=None, upper_bound=None, fixed=False)])</pre> <p>The <code>Fit</code> object takes the model, parameters and data. All symbols on the model's left-hand side (dictionary values) must be given either as parameter or data.</p> In\u00a0[4]: Copied! <pre>from slimfit.fit import Fit\n\nfit = Fit(model, parameters=parameters, data=DATA)\nresult = fit.execute()\nresult.parameters\n</pre> from slimfit.fit import Fit  fit = Fit(model, parameters=parameters, data=DATA) result = fit.execute() result.parameters Out[4]: <pre>{'a': array(0.49614865), 'b': array(2.5628281)}</pre> <p>The fit result can be evaluated by calling the model and plotting the data together with the fit result.</p> In\u00a0[5]: Copied! <pre>import proplot as pplt\n\nfig, ax = pplt.subplots()\nax.scatter(DATA[\"x\"], DATA[\"y\"])\nax.plot(DATA[\"x\"], model(**result.parameters, **DATA)[\"y\"], color=\"r\")\nax.format(xlabel=\"x\", ylabel=\"y\")\npplt.show()\n</pre> import proplot as pplt  fig, ax = pplt.subplots() ax.scatter(DATA[\"x\"], DATA[\"y\"]) ax.plot(DATA[\"x\"], model(**result.parameters, **DATA)[\"y\"], color=\"r\") ax.format(xlabel=\"x\", ylabel=\"y\") pplt.show() <p>Models can be expanded to include more datasets, such that parameters shared between entries are part of a global fit. The previous example can be expanded to include an additional datasets, where the symbol <code>b</code> is shared between both datasets:</p> In\u00a0[5]: Copied! <pre>from sympy import sin\n\nglobal_model = Model(\n    {\n        Symbol(\"y\"): Symbol(\"a\") * Symbol(\"x\") + Symbol(\"b\"),\n        Symbol(\"z\"): Symbol(\"u\") * sin(Symbol(\"t\") + Symbol(\"phi\")) + Symbol(\"b\"),\n    }\n)\nglobal_model\n</pre> from sympy import sin  global_model = Model(     {         Symbol(\"y\"): Symbol(\"a\") * Symbol(\"x\") + Symbol(\"b\"),         Symbol(\"z\"): Symbol(\"u\") * sin(Symbol(\"t\") + Symbol(\"phi\")) + Symbol(\"b\"),     } ) global_model Out[5]: <pre>Model({y: a*x + b, z: b + u*sin(phi + t)})</pre> <p>Symbols (and parameters) can have arbitrary shapes such that numpy's broadcasting rules can be taken advantage of when creating models:</p> In\u00a0[6]: Copied! <pre>phase = np.array([0.24 * np.pi, 0.8 * np.pi, 1.3 * np.pi]).reshape(3, 1)\nu = np.array([1, 1.35, 1.45]).reshape(3, 1)\ntdata = np.linspace(0, 11, num=25) + np.random.normal(size=25, scale=0.25)\nzdata = u * np.sin(tdata + phase) + gt[\"b\"]\n\nGLOBAL_DATA = {\"t\": tdata, \"z\": zdata, **DATA}\nzdata.shape\n</pre> phase = np.array([0.24 * np.pi, 0.8 * np.pi, 1.3 * np.pi]).reshape(3, 1) u = np.array([1, 1.35, 1.45]).reshape(3, 1) tdata = np.linspace(0, 11, num=25) + np.random.normal(size=25, scale=0.25) zdata = u * np.sin(tdata + phase) + gt[\"b\"]  GLOBAL_DATA = {\"t\": tdata, \"z\": zdata, **DATA} zdata.shape Out[6]: <pre>(3, 25)</pre> <p>The shape information has to be provided to <code>Fit</code> via the shape of parameter initial guesses. The parameters are bounded as multiple solutions exist due to the periodicity of the sine wave.</p> In\u00a0[7]: Copied! <pre>from slimfit import Parameter\n\nsymbols = {s.name: s for s in global_model.symbols}\nsin_parameters = Parameters(\n    [\n        Parameter(symbols[\"phi\"], guess=np.ones((3, 1)), lower_bound=0, upper_bound=2 * np.pi),\n        Parameter(symbols[\"u\"], guess=np.ones((3, 1)), lower_bound=0.5),\n    ]\n)\n</pre> from slimfit import Parameter  symbols = {s.name: s for s in global_model.symbols} sin_parameters = Parameters(     [         Parameter(symbols[\"phi\"], guess=np.ones((3, 1)), lower_bound=0, upper_bound=2 * np.pi),         Parameter(symbols[\"u\"], guess=np.ones((3, 1)), lower_bound=0.5),     ] ) In\u00a0[8]: Copied! <pre>global_parameters = parameters + sin_parameters\n</pre> global_parameters = parameters + sin_parameters In\u00a0[9]: Copied! <pre>fit = Fit(global_model, parameters=global_parameters, data=GLOBAL_DATA)\nglobal_result = fit.execute()\n\nglobal_result.parameters, global_result.parameters[\"phi\"] / np.pi\n</pre> fit = Fit(global_model, parameters=global_parameters, data=GLOBAL_DATA) global_result = fit.execute()  global_result.parameters, global_result.parameters[\"phi\"] / np.pi Out[9]: <pre>({'a': array(0.50245059),\n  'b': array(2.51637641),\n  'phi': array([[0.75814557],\n         [2.51368689],\n         [4.08105098]]),\n  'u': array([[0.99866011],\n         [1.35447098],\n         [1.45066934]])},\n array([[0.24132523],\n        [0.80013139],\n        [1.29903887]]))</pre> <p>Due to the periodicity of the sine wave and the lack of parameter constraints, the returned parameter values differ from the ground truth, however</p> In\u00a0[12]: Copied! <pre>import proplot as pplt\nfix, axes = pplt.subplots(ncols=2, share=False)\n\naxes[0].scatter(xdata, ydata)\naxes[0].axline((0, result.parameters[\"b\"]), slope=result.parameters[\"a\"], color=\"r\")\naxes[0].axline(\n    (0, global_result.parameters[\"b\"]),\n    slope=global_result.parameters[\"a\"],\n    color=\"k\",\n    linestyle=\"--\",\n)\naxes[0].format(xlabel=\"x\", ylabel=\"y\")\n\ntvec = np.linspace(0, 11, num=250)\nz_eval = global_model.numerical[\"z\"](**global_result.parameters, t=tvec, f=1.2)\n\naxes[1].plot(tvec, z_eval.T, cycle=\"default\")\naxes[1].scatter(tdata, zdata.T)\naxes[1].format(xlabel=\"t\", ylabel=\"z\")\npplt.show()\n</pre> import proplot as pplt fix, axes = pplt.subplots(ncols=2, share=False)  axes[0].scatter(xdata, ydata) axes[0].axline((0, result.parameters[\"b\"]), slope=result.parameters[\"a\"], color=\"r\") axes[0].axline(     (0, global_result.parameters[\"b\"]),     slope=global_result.parameters[\"a\"],     color=\"k\",     linestyle=\"--\", ) axes[0].format(xlabel=\"x\", ylabel=\"y\")  tvec = np.linspace(0, 11, num=250) z_eval = global_model.numerical[\"z\"](**global_result.parameters, t=tvec, f=1.2)  axes[1].plot(tvec, z_eval.T, cycle=\"default\") axes[1].scatter(tdata, zdata.T) axes[1].format(xlabel=\"t\", ylabel=\"z\") pplt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}]}